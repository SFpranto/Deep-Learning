{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b10547d4d78b448ab156d8353ed35522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a42167164a34eb3ae8853877b413f13",
              "IPY_MODEL_73da59bef44c4bfdbda45931748ea084",
              "IPY_MODEL_e676312775b342578c0b56fc173c99af"
            ],
            "layout": "IPY_MODEL_fd8671e6e22641c1ac238d47bbe0a5a2"
          }
        },
        "3a42167164a34eb3ae8853877b413f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c59da1efc453417093d4eebf12bf7cd8",
            "placeholder": "​",
            "style": "IPY_MODEL_2fee1bbf420b4adf827fefa6d2b8b236",
            "value": "model.safetensors: 100%"
          }
        },
        "73da59bef44c4bfdbda45931748ea084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8ac42ea8f24c00b4dd92d4b3dcca21",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1399502569ec400c8f90f514f7eb0d99",
            "value": 267954768
          }
        },
        "e676312775b342578c0b56fc173c99af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2572530994694e30b75cd055bcc47975",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d78a9a4e844de497b5614a0c80533e",
            "value": " 268M/268M [00:11&lt;00:00, 20.4MB/s]"
          }
        },
        "fd8671e6e22641c1ac238d47bbe0a5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59da1efc453417093d4eebf12bf7cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fee1bbf420b4adf827fefa6d2b8b236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e8ac42ea8f24c00b4dd92d4b3dcca21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1399502569ec400c8f90f514f7eb0d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2572530994694e30b75cd055bcc47975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d78a9a4e844de497b5614a0c80533e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b10547d4d78b448ab156d8353ed35522",
            "3a42167164a34eb3ae8853877b413f13",
            "73da59bef44c4bfdbda45931748ea084",
            "e676312775b342578c0b56fc173c99af",
            "fd8671e6e22641c1ac238d47bbe0a5a2",
            "c59da1efc453417093d4eebf12bf7cd8",
            "2fee1bbf420b4adf827fefa6d2b8b236",
            "2e8ac42ea8f24c00b4dd92d4b3dcca21",
            "1399502569ec400c8f90f514f7eb0d99",
            "2572530994694e30b75cd055bcc47975",
            "b9d78a9a4e844de497b5614a0c80533e"
          ]
        },
        "id": "-o4pPIgwhvFw",
        "outputId": "de3b91c2-0676-40b1-81af-3824ba73fe9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cuda\n",
            "Loading DistilBERT model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b10547d4d78b448ab156d8353ed35522"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Starting training...\n",
            "\n",
            "Epoch 1\n",
            "Batch 0/4125 - Loss: 0.6688 - Time elapsed: 1.21s\n",
            "Batch 10/4125 - Loss: 0.6304 - Time elapsed: 2.94s\n",
            "Batch 20/4125 - Loss: 0.4421 - Time elapsed: 4.64s\n",
            "Batch 30/4125 - Loss: 0.2240 - Time elapsed: 6.25s\n",
            "Batch 40/4125 - Loss: 0.1818 - Time elapsed: 7.87s\n",
            "Batch 50/4125 - Loss: 0.3256 - Time elapsed: 10.12s\n",
            "Batch 60/4125 - Loss: 0.2564 - Time elapsed: 11.75s\n",
            "Batch 70/4125 - Loss: 0.2407 - Time elapsed: 13.42s\n",
            "Batch 80/4125 - Loss: 0.4318 - Time elapsed: 15.07s\n",
            "Batch 90/4125 - Loss: 0.0696 - Time elapsed: 16.75s\n",
            "Batch 100/4125 - Loss: 0.2205 - Time elapsed: 18.69s\n",
            "Batch 110/4125 - Loss: 0.1504 - Time elapsed: 20.33s\n",
            "Batch 120/4125 - Loss: 0.1332 - Time elapsed: 22.00s\n",
            "Batch 130/4125 - Loss: 0.1051 - Time elapsed: 23.72s\n",
            "Batch 140/4125 - Loss: 0.1431 - Time elapsed: 25.37s\n",
            "Batch 150/4125 - Loss: 0.0315 - Time elapsed: 27.09s\n",
            "Batch 160/4125 - Loss: 0.0898 - Time elapsed: 28.95s\n",
            "Batch 170/4125 - Loss: 0.1240 - Time elapsed: 30.63s\n",
            "Batch 180/4125 - Loss: 0.1228 - Time elapsed: 32.32s\n",
            "Batch 190/4125 - Loss: 0.0314 - Time elapsed: 33.99s\n",
            "Batch 200/4125 - Loss: 0.0324 - Time elapsed: 35.76s\n",
            "Batch 210/4125 - Loss: 0.2717 - Time elapsed: 37.44s\n",
            "Batch 220/4125 - Loss: 0.3058 - Time elapsed: 39.12s\n",
            "Batch 230/4125 - Loss: 0.1327 - Time elapsed: 40.81s\n",
            "Batch 240/4125 - Loss: 0.0332 - Time elapsed: 42.53s\n",
            "Batch 250/4125 - Loss: 0.0393 - Time elapsed: 44.33s\n",
            "Batch 260/4125 - Loss: 0.0385 - Time elapsed: 47.23s\n",
            "Batch 270/4125 - Loss: 0.1977 - Time elapsed: 48.94s\n",
            "Batch 280/4125 - Loss: 0.0153 - Time elapsed: 50.65s\n",
            "Batch 290/4125 - Loss: 0.1306 - Time elapsed: 52.37s\n",
            "Batch 300/4125 - Loss: 0.0349 - Time elapsed: 54.19s\n",
            "Batch 310/4125 - Loss: 0.0355 - Time elapsed: 56.00s\n",
            "Batch 320/4125 - Loss: 0.0245 - Time elapsed: 57.77s\n",
            "Batch 330/4125 - Loss: 0.0662 - Time elapsed: 59.58s\n",
            "Batch 340/4125 - Loss: 0.0205 - Time elapsed: 61.35s\n",
            "Batch 350/4125 - Loss: 0.3687 - Time elapsed: 63.10s\n",
            "Batch 360/4125 - Loss: 0.0830 - Time elapsed: 64.86s\n",
            "Batch 370/4125 - Loss: 0.4228 - Time elapsed: 66.62s\n",
            "Batch 380/4125 - Loss: 0.0526 - Time elapsed: 68.41s\n",
            "Batch 390/4125 - Loss: 0.1226 - Time elapsed: 70.40s\n",
            "Batch 400/4125 - Loss: 0.0286 - Time elapsed: 72.20s\n",
            "Batch 410/4125 - Loss: 0.0713 - Time elapsed: 73.97s\n",
            "Batch 420/4125 - Loss: 0.0069 - Time elapsed: 75.75s\n",
            "Batch 430/4125 - Loss: 0.0900 - Time elapsed: 77.60s\n",
            "Batch 440/4125 - Loss: 0.0160 - Time elapsed: 79.42s\n",
            "Batch 450/4125 - Loss: 0.3413 - Time elapsed: 81.32s\n",
            "Batch 460/4125 - Loss: 0.0194 - Time elapsed: 83.48s\n",
            "Batch 470/4125 - Loss: 0.0102 - Time elapsed: 85.32s\n",
            "Batch 480/4125 - Loss: 0.0108 - Time elapsed: 87.38s\n",
            "Batch 490/4125 - Loss: 0.0153 - Time elapsed: 89.19s\n",
            "Batch 500/4125 - Loss: 0.0164 - Time elapsed: 91.67s\n",
            "Batch 510/4125 - Loss: 0.0591 - Time elapsed: 93.51s\n",
            "Batch 520/4125 - Loss: 0.0587 - Time elapsed: 95.32s\n",
            "Batch 530/4125 - Loss: 0.0124 - Time elapsed: 97.27s\n",
            "Batch 540/4125 - Loss: 0.0511 - Time elapsed: 99.08s\n",
            "Batch 550/4125 - Loss: 0.0093 - Time elapsed: 100.97s\n",
            "Batch 560/4125 - Loss: 0.0039 - Time elapsed: 102.84s\n",
            "Batch 570/4125 - Loss: 0.0158 - Time elapsed: 104.72s\n",
            "Batch 580/4125 - Loss: 0.1722 - Time elapsed: 106.58s\n",
            "Batch 590/4125 - Loss: 0.2155 - Time elapsed: 108.58s\n",
            "Batch 600/4125 - Loss: 0.0439 - Time elapsed: 110.63s\n",
            "Batch 610/4125 - Loss: 0.0435 - Time elapsed: 112.47s\n",
            "Batch 620/4125 - Loss: 0.0340 - Time elapsed: 114.33s\n",
            "Batch 630/4125 - Loss: 0.0179 - Time elapsed: 116.18s\n",
            "Batch 640/4125 - Loss: 0.0579 - Time elapsed: 118.10s\n",
            "Batch 650/4125 - Loss: 0.0033 - Time elapsed: 119.96s\n",
            "Batch 660/4125 - Loss: 0.0422 - Time elapsed: 121.95s\n",
            "Batch 670/4125 - Loss: 0.0377 - Time elapsed: 123.82s\n",
            "Batch 680/4125 - Loss: 0.0183 - Time elapsed: 125.67s\n",
            "Batch 690/4125 - Loss: 0.1783 - Time elapsed: 127.56s\n",
            "Batch 700/4125 - Loss: 0.1245 - Time elapsed: 129.46s\n",
            "Batch 710/4125 - Loss: 0.5080 - Time elapsed: 131.28s\n",
            "Batch 720/4125 - Loss: 0.0181 - Time elapsed: 133.13s\n",
            "Batch 730/4125 - Loss: 0.0521 - Time elapsed: 135.04s\n",
            "Batch 740/4125 - Loss: 0.1328 - Time elapsed: 136.88s\n",
            "Batch 750/4125 - Loss: 0.0224 - Time elapsed: 138.72s\n",
            "Batch 760/4125 - Loss: 0.0556 - Time elapsed: 140.62s\n",
            "Batch 770/4125 - Loss: 0.0096 - Time elapsed: 142.47s\n",
            "Batch 780/4125 - Loss: 0.0068 - Time elapsed: 144.30s\n",
            "Batch 790/4125 - Loss: 0.0113 - Time elapsed: 146.08s\n",
            "Batch 800/4125 - Loss: 0.0771 - Time elapsed: 147.91s\n",
            "Batch 810/4125 - Loss: 0.0054 - Time elapsed: 149.74s\n",
            "Batch 820/4125 - Loss: 0.3033 - Time elapsed: 151.60s\n",
            "Batch 830/4125 - Loss: 0.0096 - Time elapsed: 153.46s\n",
            "Batch 840/4125 - Loss: 0.0180 - Time elapsed: 155.29s\n",
            "Batch 850/4125 - Loss: 0.0205 - Time elapsed: 159.05s\n",
            "Batch 860/4125 - Loss: 0.0129 - Time elapsed: 160.81s\n",
            "Batch 870/4125 - Loss: 0.1477 - Time elapsed: 163.94s\n",
            "Batch 880/4125 - Loss: 0.0070 - Time elapsed: 165.72s\n",
            "Batch 890/4125 - Loss: 0.2263 - Time elapsed: 167.47s\n",
            "Batch 900/4125 - Loss: 0.0613 - Time elapsed: 169.28s\n",
            "Batch 910/4125 - Loss: 0.0096 - Time elapsed: 171.08s\n",
            "Batch 920/4125 - Loss: 0.0032 - Time elapsed: 173.16s\n",
            "Batch 930/4125 - Loss: 0.0029 - Time elapsed: 175.05s\n",
            "Batch 940/4125 - Loss: 0.1184 - Time elapsed: 176.99s\n",
            "Batch 950/4125 - Loss: 0.0225 - Time elapsed: 178.87s\n",
            "Batch 960/4125 - Loss: 0.0157 - Time elapsed: 180.72s\n",
            "Batch 970/4125 - Loss: 0.0050 - Time elapsed: 182.57s\n",
            "Batch 980/4125 - Loss: 0.0154 - Time elapsed: 184.41s\n",
            "Batch 990/4125 - Loss: 0.0679 - Time elapsed: 186.22s\n",
            "Batch 1000/4125 - Loss: 0.1357 - Time elapsed: 188.33s\n",
            "Batch 1010/4125 - Loss: 0.0416 - Time elapsed: 193.21s\n",
            "Batch 1020/4125 - Loss: 0.0141 - Time elapsed: 195.01s\n",
            "Batch 1030/4125 - Loss: 0.0080 - Time elapsed: 196.81s\n",
            "Batch 1040/4125 - Loss: 0.0095 - Time elapsed: 198.63s\n",
            "Batch 1050/4125 - Loss: 0.0314 - Time elapsed: 200.54s\n",
            "Batch 1060/4125 - Loss: 0.0162 - Time elapsed: 202.40s\n",
            "Batch 1070/4125 - Loss: 0.0027 - Time elapsed: 204.26s\n",
            "Batch 1080/4125 - Loss: 0.0044 - Time elapsed: 206.28s\n",
            "Batch 1090/4125 - Loss: 0.0633 - Time elapsed: 208.17s\n",
            "Batch 1100/4125 - Loss: 0.0044 - Time elapsed: 210.00s\n",
            "Batch 1110/4125 - Loss: 0.0019 - Time elapsed: 211.85s\n",
            "Batch 1120/4125 - Loss: 0.0569 - Time elapsed: 214.02s\n",
            "Batch 1130/4125 - Loss: 0.0445 - Time elapsed: 215.95s\n",
            "Batch 1140/4125 - Loss: 0.0495 - Time elapsed: 217.77s\n",
            "Batch 1150/4125 - Loss: 0.0136 - Time elapsed: 222.82s\n",
            "Batch 1160/4125 - Loss: 0.0009 - Time elapsed: 224.61s\n",
            "Batch 1170/4125 - Loss: 0.1353 - Time elapsed: 226.54s\n",
            "Batch 1180/4125 - Loss: 0.0107 - Time elapsed: 228.48s\n",
            "Batch 1190/4125 - Loss: 0.0307 - Time elapsed: 230.32s\n",
            "Batch 1200/4125 - Loss: 0.0329 - Time elapsed: 232.11s\n",
            "Batch 1210/4125 - Loss: 0.0069 - Time elapsed: 233.90s\n",
            "Batch 1220/4125 - Loss: 0.0064 - Time elapsed: 235.68s\n",
            "Batch 1230/4125 - Loss: 0.0055 - Time elapsed: 237.51s\n",
            "Batch 1240/4125 - Loss: 0.0199 - Time elapsed: 239.43s\n",
            "Batch 1250/4125 - Loss: 0.0165 - Time elapsed: 241.24s\n",
            "Batch 1260/4125 - Loss: 0.0833 - Time elapsed: 243.05s\n",
            "Batch 1270/4125 - Loss: 0.0016 - Time elapsed: 244.86s\n",
            "Batch 1280/4125 - Loss: 0.0669 - Time elapsed: 246.66s\n",
            "Batch 1290/4125 - Loss: 0.0055 - Time elapsed: 248.48s\n",
            "Batch 1300/4125 - Loss: 0.0181 - Time elapsed: 250.28s\n",
            "Batch 1310/4125 - Loss: 0.0030 - Time elapsed: 252.07s\n",
            "Batch 1320/4125 - Loss: 0.0069 - Time elapsed: 253.95s\n",
            "Batch 1330/4125 - Loss: 0.0022 - Time elapsed: 255.89s\n",
            "Batch 1340/4125 - Loss: 0.0210 - Time elapsed: 257.70s\n",
            "Batch 1350/4125 - Loss: 0.0517 - Time elapsed: 259.54s\n",
            "Batch 1360/4125 - Loss: 0.0193 - Time elapsed: 261.37s\n",
            "Batch 1370/4125 - Loss: 0.0534 - Time elapsed: 263.17s\n",
            "Batch 1380/4125 - Loss: 0.0039 - Time elapsed: 264.98s\n",
            "Batch 1390/4125 - Loss: 0.0156 - Time elapsed: 266.85s\n",
            "Batch 1400/4125 - Loss: 0.0021 - Time elapsed: 268.71s\n",
            "Batch 1410/4125 - Loss: 0.0023 - Time elapsed: 270.52s\n",
            "Batch 1420/4125 - Loss: 0.0077 - Time elapsed: 272.35s\n",
            "Batch 1430/4125 - Loss: 0.1019 - Time elapsed: 274.12s\n",
            "Batch 1440/4125 - Loss: 0.0183 - Time elapsed: 275.94s\n",
            "Batch 1450/4125 - Loss: 0.0082 - Time elapsed: 277.73s\n",
            "Batch 1460/4125 - Loss: 0.0308 - Time elapsed: 279.57s\n",
            "Batch 1470/4125 - Loss: 0.1637 - Time elapsed: 281.50s\n",
            "Batch 1480/4125 - Loss: 0.0110 - Time elapsed: 283.29s\n",
            "Batch 1490/4125 - Loss: 0.0064 - Time elapsed: 285.09s\n",
            "Batch 1500/4125 - Loss: 0.0063 - Time elapsed: 286.93s\n",
            "Batch 1510/4125 - Loss: 0.0050 - Time elapsed: 288.75s\n",
            "Batch 1520/4125 - Loss: 0.0054 - Time elapsed: 290.76s\n",
            "Batch 1530/4125 - Loss: 0.0046 - Time elapsed: 292.85s\n",
            "Batch 1540/4125 - Loss: 0.0324 - Time elapsed: 294.73s\n",
            "Batch 1550/4125 - Loss: 0.0277 - Time elapsed: 296.57s\n",
            "Batch 1560/4125 - Loss: 0.0020 - Time elapsed: 298.39s\n",
            "Batch 1570/4125 - Loss: 0.0038 - Time elapsed: 300.18s\n",
            "Batch 1580/4125 - Loss: 0.0938 - Time elapsed: 302.02s\n",
            "Batch 1590/4125 - Loss: 0.0072 - Time elapsed: 303.85s\n",
            "Batch 1600/4125 - Loss: 0.0088 - Time elapsed: 305.70s\n",
            "Batch 1610/4125 - Loss: 0.0060 - Time elapsed: 307.62s\n",
            "Batch 1620/4125 - Loss: 0.0031 - Time elapsed: 309.45s\n",
            "Batch 1630/4125 - Loss: 0.0012 - Time elapsed: 311.26s\n",
            "Batch 1640/4125 - Loss: 0.0019 - Time elapsed: 313.08s\n",
            "Batch 1650/4125 - Loss: 0.0103 - Time elapsed: 314.86s\n",
            "Batch 1660/4125 - Loss: 0.0034 - Time elapsed: 316.67s\n",
            "Batch 1670/4125 - Loss: 0.0025 - Time elapsed: 318.58s\n",
            "Batch 1680/4125 - Loss: 0.0027 - Time elapsed: 320.53s\n",
            "Batch 1690/4125 - Loss: 0.0156 - Time elapsed: 322.35s\n",
            "Batch 1700/4125 - Loss: 0.3138 - Time elapsed: 324.53s\n",
            "Batch 1710/4125 - Loss: 0.0098 - Time elapsed: 326.36s\n",
            "Batch 1720/4125 - Loss: 0.0395 - Time elapsed: 328.39s\n",
            "Batch 1730/4125 - Loss: 0.0196 - Time elapsed: 330.20s\n",
            "Batch 1740/4125 - Loss: 0.0024 - Time elapsed: 332.09s\n",
            "Batch 1750/4125 - Loss: 0.0018 - Time elapsed: 333.98s\n",
            "Batch 1760/4125 - Loss: 0.0050 - Time elapsed: 335.80s\n",
            "Batch 1770/4125 - Loss: 0.0036 - Time elapsed: 337.59s\n",
            "Batch 1780/4125 - Loss: 0.0879 - Time elapsed: 339.37s\n",
            "Batch 1790/4125 - Loss: 0.0471 - Time elapsed: 341.19s\n",
            "Batch 1800/4125 - Loss: 0.1102 - Time elapsed: 342.99s\n",
            "Batch 1810/4125 - Loss: 0.0047 - Time elapsed: 344.90s\n",
            "Batch 1820/4125 - Loss: 0.0056 - Time elapsed: 346.85s\n",
            "Batch 1830/4125 - Loss: 0.0048 - Time elapsed: 348.81s\n",
            "Batch 1840/4125 - Loss: 0.0612 - Time elapsed: 351.06s\n",
            "Batch 1850/4125 - Loss: 0.0029 - Time elapsed: 352.86s\n",
            "Batch 1860/4125 - Loss: 0.0050 - Time elapsed: 355.19s\n",
            "Batch 1870/4125 - Loss: 0.0026 - Time elapsed: 357.02s\n",
            "Batch 1880/4125 - Loss: 0.0352 - Time elapsed: 358.92s\n",
            "Batch 1890/4125 - Loss: 0.0007 - Time elapsed: 360.79s\n",
            "Batch 1900/4125 - Loss: 0.0079 - Time elapsed: 362.60s\n",
            "Batch 1910/4125 - Loss: 0.1043 - Time elapsed: 364.40s\n",
            "Batch 1920/4125 - Loss: 0.3429 - Time elapsed: 366.20s\n",
            "Batch 1930/4125 - Loss: 0.0456 - Time elapsed: 367.99s\n",
            "Batch 1940/4125 - Loss: 0.0028 - Time elapsed: 370.04s\n",
            "Batch 1950/4125 - Loss: 0.0149 - Time elapsed: 372.00s\n",
            "Batch 1960/4125 - Loss: 0.0526 - Time elapsed: 373.85s\n",
            "Batch 1970/4125 - Loss: 0.0061 - Time elapsed: 375.66s\n",
            "Batch 1980/4125 - Loss: 0.0172 - Time elapsed: 377.50s\n",
            "Batch 1990/4125 - Loss: 0.0205 - Time elapsed: 379.29s\n",
            "Batch 2000/4125 - Loss: 0.0619 - Time elapsed: 381.12s\n",
            "Batch 2010/4125 - Loss: 0.3577 - Time elapsed: 382.96s\n",
            "Batch 2020/4125 - Loss: 0.2877 - Time elapsed: 384.79s\n",
            "Batch 2030/4125 - Loss: 0.0201 - Time elapsed: 386.84s\n",
            "Batch 2040/4125 - Loss: 0.2193 - Time elapsed: 388.64s\n",
            "Batch 2050/4125 - Loss: 0.0191 - Time elapsed: 390.44s\n",
            "Batch 2060/4125 - Loss: 0.0095 - Time elapsed: 392.99s\n",
            "Batch 2070/4125 - Loss: 0.0022 - Time elapsed: 394.89s\n",
            "Batch 2080/4125 - Loss: 0.0411 - Time elapsed: 396.69s\n",
            "Batch 2090/4125 - Loss: 0.0219 - Time elapsed: 398.53s\n",
            "Batch 2100/4125 - Loss: 0.0114 - Time elapsed: 400.36s\n",
            "Batch 2110/4125 - Loss: 0.0027 - Time elapsed: 402.25s\n",
            "Batch 2120/4125 - Loss: 0.0938 - Time elapsed: 404.08s\n",
            "Batch 2130/4125 - Loss: 0.0007 - Time elapsed: 405.91s\n",
            "Batch 2140/4125 - Loss: 0.0015 - Time elapsed: 407.79s\n",
            "Batch 2150/4125 - Loss: 0.1499 - Time elapsed: 410.09s\n",
            "Batch 2160/4125 - Loss: 0.0394 - Time elapsed: 412.07s\n",
            "Batch 2170/4125 - Loss: 0.0653 - Time elapsed: 413.88s\n",
            "Batch 2180/4125 - Loss: 0.0089 - Time elapsed: 415.68s\n",
            "Batch 2190/4125 - Loss: 0.0273 - Time elapsed: 417.50s\n",
            "Batch 2200/4125 - Loss: 0.0393 - Time elapsed: 419.34s\n",
            "Batch 2210/4125 - Loss: 0.0007 - Time elapsed: 421.33s\n",
            "Batch 2220/4125 - Loss: 0.0018 - Time elapsed: 423.44s\n",
            "Batch 2230/4125 - Loss: 0.1055 - Time elapsed: 425.32s\n",
            "Batch 2240/4125 - Loss: 0.1075 - Time elapsed: 427.14s\n",
            "Batch 2250/4125 - Loss: 0.3256 - Time elapsed: 428.93s\n",
            "Batch 2260/4125 - Loss: 0.0379 - Time elapsed: 430.75s\n",
            "Batch 2270/4125 - Loss: 0.0015 - Time elapsed: 432.56s\n",
            "Batch 2280/4125 - Loss: 0.0548 - Time elapsed: 434.56s\n",
            "Batch 2290/4125 - Loss: 0.0091 - Time elapsed: 436.45s\n",
            "Batch 2300/4125 - Loss: 0.0111 - Time elapsed: 438.41s\n",
            "Batch 2310/4125 - Loss: 0.0260 - Time elapsed: 440.24s\n",
            "Batch 2320/4125 - Loss: 0.0058 - Time elapsed: 442.06s\n",
            "Batch 2330/4125 - Loss: 0.0018 - Time elapsed: 443.85s\n",
            "Batch 2340/4125 - Loss: 0.0089 - Time elapsed: 446.39s\n",
            "Batch 2350/4125 - Loss: 0.0601 - Time elapsed: 448.26s\n",
            "Batch 2360/4125 - Loss: 0.0400 - Time elapsed: 450.15s\n",
            "Batch 2370/4125 - Loss: 0.0099 - Time elapsed: 452.04s\n",
            "Batch 2380/4125 - Loss: 0.0011 - Time elapsed: 454.97s\n",
            "Batch 2390/4125 - Loss: 0.0005 - Time elapsed: 456.87s\n",
            "Batch 2400/4125 - Loss: 0.0033 - Time elapsed: 458.70s\n",
            "Batch 2410/4125 - Loss: 0.0162 - Time elapsed: 460.67s\n",
            "Batch 2420/4125 - Loss: 0.0025 - Time elapsed: 462.52s\n",
            "Batch 2430/4125 - Loss: 0.0998 - Time elapsed: 464.49s\n",
            "Batch 2440/4125 - Loss: 0.0143 - Time elapsed: 466.31s\n",
            "Batch 2450/4125 - Loss: 0.0004 - Time elapsed: 468.11s\n",
            "Batch 2460/4125 - Loss: 0.0688 - Time elapsed: 469.93s\n",
            "Batch 2470/4125 - Loss: 0.0010 - Time elapsed: 471.78s\n",
            "Batch 2480/4125 - Loss: 0.0123 - Time elapsed: 473.60s\n",
            "Batch 2490/4125 - Loss: 0.0317 - Time elapsed: 475.39s\n",
            "Batch 2500/4125 - Loss: 0.0586 - Time elapsed: 477.35s\n",
            "Batch 2510/4125 - Loss: 0.0138 - Time elapsed: 479.16s\n",
            "Batch 2520/4125 - Loss: 0.0162 - Time elapsed: 480.96s\n",
            "Batch 2530/4125 - Loss: 0.0006 - Time elapsed: 482.76s\n",
            "Batch 2540/4125 - Loss: 0.0022 - Time elapsed: 484.55s\n",
            "Batch 2550/4125 - Loss: 0.0005 - Time elapsed: 486.35s\n",
            "Batch 2560/4125 - Loss: 0.0013 - Time elapsed: 488.14s\n",
            "Batch 2570/4125 - Loss: 0.0005 - Time elapsed: 490.01s\n",
            "Batch 2580/4125 - Loss: 0.0189 - Time elapsed: 491.88s\n",
            "Batch 2590/4125 - Loss: 0.0260 - Time elapsed: 493.69s\n",
            "Batch 2600/4125 - Loss: 0.2716 - Time elapsed: 495.58s\n",
            "Batch 2610/4125 - Loss: 0.0052 - Time elapsed: 497.39s\n",
            "Batch 2620/4125 - Loss: 0.0007 - Time elapsed: 500.19s\n",
            "Batch 2630/4125 - Loss: 0.0010 - Time elapsed: 502.00s\n",
            "Batch 2640/4125 - Loss: 0.1139 - Time elapsed: 503.90s\n",
            "Batch 2650/4125 - Loss: 0.2858 - Time elapsed: 505.70s\n",
            "Batch 2660/4125 - Loss: 0.0297 - Time elapsed: 507.56s\n",
            "Batch 2670/4125 - Loss: 0.0018 - Time elapsed: 509.39s\n",
            "Batch 2680/4125 - Loss: 0.0006 - Time elapsed: 511.22s\n",
            "Batch 2690/4125 - Loss: 0.0094 - Time elapsed: 513.06s\n",
            "Batch 2700/4125 - Loss: 0.0031 - Time elapsed: 515.10s\n",
            "Batch 2710/4125 - Loss: 0.0095 - Time elapsed: 517.24s\n",
            "Batch 2720/4125 - Loss: 0.0293 - Time elapsed: 519.04s\n",
            "Batch 2730/4125 - Loss: 0.0011 - Time elapsed: 520.86s\n",
            "Batch 2740/4125 - Loss: 0.0025 - Time elapsed: 522.70s\n",
            "Batch 2750/4125 - Loss: 0.0044 - Time elapsed: 524.50s\n",
            "Batch 2760/4125 - Loss: 0.0465 - Time elapsed: 526.31s\n",
            "Batch 2770/4125 - Loss: 0.0140 - Time elapsed: 528.14s\n",
            "Batch 2780/4125 - Loss: 0.0231 - Time elapsed: 530.01s\n",
            "Batch 2790/4125 - Loss: 0.1832 - Time elapsed: 531.83s\n",
            "Batch 2800/4125 - Loss: 0.1271 - Time elapsed: 533.65s\n",
            "Batch 2810/4125 - Loss: 0.0248 - Time elapsed: 535.46s\n",
            "Batch 2820/4125 - Loss: 0.0094 - Time elapsed: 537.34s\n",
            "Batch 2830/4125 - Loss: 0.0097 - Time elapsed: 539.19s\n",
            "Batch 2840/4125 - Loss: 0.0058 - Time elapsed: 541.29s\n",
            "Batch 2850/4125 - Loss: 0.0749 - Time elapsed: 543.18s\n",
            "Batch 2860/4125 - Loss: 0.0030 - Time elapsed: 545.16s\n",
            "Batch 2870/4125 - Loss: 0.1484 - Time elapsed: 547.11s\n",
            "Batch 2880/4125 - Loss: 0.0035 - Time elapsed: 548.92s\n",
            "Batch 2890/4125 - Loss: 0.0036 - Time elapsed: 550.74s\n",
            "Batch 2900/4125 - Loss: 0.0073 - Time elapsed: 552.60s\n",
            "Batch 2910/4125 - Loss: 0.0042 - Time elapsed: 554.43s\n",
            "Batch 2920/4125 - Loss: 0.0026 - Time elapsed: 556.26s\n",
            "Batch 2930/4125 - Loss: 0.0069 - Time elapsed: 558.12s\n",
            "Batch 2940/4125 - Loss: 0.0910 - Time elapsed: 559.95s\n",
            "Batch 2950/4125 - Loss: 0.0037 - Time elapsed: 561.80s\n",
            "Batch 2960/4125 - Loss: 0.0257 - Time elapsed: 563.65s\n",
            "Batch 2970/4125 - Loss: 0.3195 - Time elapsed: 565.48s\n",
            "Batch 2980/4125 - Loss: 0.0628 - Time elapsed: 567.29s\n",
            "Batch 2990/4125 - Loss: 0.1032 - Time elapsed: 569.15s\n",
            "Batch 3000/4125 - Loss: 0.0178 - Time elapsed: 571.07s\n",
            "Batch 3010/4125 - Loss: 0.1416 - Time elapsed: 572.91s\n",
            "Batch 3020/4125 - Loss: 0.0111 - Time elapsed: 574.79s\n",
            "Batch 3030/4125 - Loss: 0.0144 - Time elapsed: 576.65s\n",
            "Batch 3040/4125 - Loss: 0.0008 - Time elapsed: 578.51s\n",
            "Batch 3050/4125 - Loss: 0.0040 - Time elapsed: 580.31s\n",
            "Batch 3060/4125 - Loss: 0.0040 - Time elapsed: 582.44s\n",
            "Batch 3070/4125 - Loss: 0.0019 - Time elapsed: 584.27s\n",
            "Batch 3080/4125 - Loss: 0.0011 - Time elapsed: 586.13s\n",
            "Batch 3090/4125 - Loss: 0.0772 - Time elapsed: 587.91s\n",
            "Batch 3100/4125 - Loss: 0.0058 - Time elapsed: 589.72s\n",
            "Batch 3110/4125 - Loss: 0.0009 - Time elapsed: 591.52s\n",
            "Batch 3120/4125 - Loss: 0.0019 - Time elapsed: 593.52s\n",
            "Batch 3130/4125 - Loss: 0.0086 - Time elapsed: 595.78s\n",
            "Batch 3140/4125 - Loss: 0.0117 - Time elapsed: 597.61s\n",
            "Batch 3150/4125 - Loss: 0.0048 - Time elapsed: 599.47s\n",
            "Batch 3160/4125 - Loss: 0.0006 - Time elapsed: 601.27s\n",
            "Batch 3170/4125 - Loss: 0.0004 - Time elapsed: 603.09s\n",
            "Batch 3180/4125 - Loss: 0.1026 - Time elapsed: 604.91s\n",
            "Batch 3190/4125 - Loss: 0.0037 - Time elapsed: 606.83s\n",
            "Batch 3200/4125 - Loss: 0.0014 - Time elapsed: 608.79s\n",
            "Batch 3210/4125 - Loss: 0.0011 - Time elapsed: 610.70s\n",
            "Batch 3220/4125 - Loss: 0.0050 - Time elapsed: 612.49s\n",
            "Batch 3230/4125 - Loss: 0.0054 - Time elapsed: 614.29s\n",
            "Batch 3240/4125 - Loss: 0.1712 - Time elapsed: 616.30s\n",
            "Batch 3250/4125 - Loss: 0.0017 - Time elapsed: 618.12s\n",
            "Batch 3260/4125 - Loss: 0.0027 - Time elapsed: 620.16s\n",
            "Batch 3270/4125 - Loss: 0.0076 - Time elapsed: 622.06s\n",
            "Batch 3280/4125 - Loss: 0.1702 - Time elapsed: 623.96s\n",
            "Batch 3290/4125 - Loss: 0.0026 - Time elapsed: 625.75s\n",
            "Batch 3300/4125 - Loss: 0.1578 - Time elapsed: 627.55s\n",
            "Batch 3310/4125 - Loss: 0.0022 - Time elapsed: 629.39s\n",
            "Batch 3320/4125 - Loss: 0.0092 - Time elapsed: 631.71s\n",
            "Batch 3330/4125 - Loss: 0.0015 - Time elapsed: 633.58s\n",
            "Batch 3340/4125 - Loss: 0.0043 - Time elapsed: 635.48s\n",
            "Batch 3350/4125 - Loss: 0.0593 - Time elapsed: 637.28s\n",
            "Batch 3360/4125 - Loss: 0.0087 - Time elapsed: 639.07s\n",
            "Batch 3370/4125 - Loss: 0.0049 - Time elapsed: 640.86s\n",
            "Batch 3380/4125 - Loss: 0.1059 - Time elapsed: 642.71s\n",
            "Batch 3390/4125 - Loss: 0.0009 - Time elapsed: 644.50s\n",
            "Batch 3400/4125 - Loss: 0.0029 - Time elapsed: 646.27s\n",
            "Batch 3410/4125 - Loss: 0.0020 - Time elapsed: 648.27s\n",
            "Batch 3420/4125 - Loss: 0.0511 - Time elapsed: 650.22s\n",
            "Batch 3430/4125 - Loss: 0.0010 - Time elapsed: 652.02s\n",
            "Batch 3440/4125 - Loss: 0.0019 - Time elapsed: 654.10s\n",
            "Batch 3450/4125 - Loss: 0.0011 - Time elapsed: 655.89s\n",
            "Batch 3460/4125 - Loss: 0.0068 - Time elapsed: 657.76s\n",
            "Batch 3470/4125 - Loss: 0.0020 - Time elapsed: 659.73s\n",
            "Batch 3480/4125 - Loss: 0.0016 - Time elapsed: 662.19s\n",
            "Batch 3490/4125 - Loss: 0.0147 - Time elapsed: 663.98s\n",
            "Batch 3500/4125 - Loss: 0.0031 - Time elapsed: 665.77s\n",
            "Batch 3510/4125 - Loss: 0.0040 - Time elapsed: 667.57s\n",
            "Batch 3520/4125 - Loss: 0.0107 - Time elapsed: 669.39s\n",
            "Batch 3530/4125 - Loss: 0.0063 - Time elapsed: 671.23s\n",
            "Batch 3540/4125 - Loss: 0.0004 - Time elapsed: 673.04s\n",
            "Batch 3550/4125 - Loss: 0.0390 - Time elapsed: 674.89s\n",
            "Batch 3560/4125 - Loss: 0.0012 - Time elapsed: 676.93s\n",
            "Batch 3570/4125 - Loss: 0.0013 - Time elapsed: 678.73s\n",
            "Batch 3580/4125 - Loss: 0.0126 - Time elapsed: 680.53s\n",
            "Batch 3590/4125 - Loss: 0.0032 - Time elapsed: 682.33s\n",
            "Batch 3600/4125 - Loss: 0.0026 - Time elapsed: 684.13s\n",
            "Batch 3610/4125 - Loss: 0.0654 - Time elapsed: 686.03s\n",
            "Batch 3620/4125 - Loss: 0.0402 - Time elapsed: 688.38s\n",
            "Batch 3630/4125 - Loss: 0.0208 - Time elapsed: 690.18s\n",
            "Batch 3640/4125 - Loss: 0.1148 - Time elapsed: 759.22s\n",
            "Batch 3650/4125 - Loss: 0.0012 - Time elapsed: 761.01s\n",
            "Batch 3660/4125 - Loss: 0.0081 - Time elapsed: 762.81s\n",
            "Batch 3670/4125 - Loss: 0.0010 - Time elapsed: 764.63s\n",
            "Batch 3680/4125 - Loss: 0.0307 - Time elapsed: 766.49s\n",
            "Batch 3690/4125 - Loss: 0.0013 - Time elapsed: 768.53s\n",
            "Batch 3700/4125 - Loss: 0.0530 - Time elapsed: 770.39s\n",
            "Batch 3710/4125 - Loss: 0.0011 - Time elapsed: 772.23s\n",
            "Batch 3720/4125 - Loss: 0.0234 - Time elapsed: 774.08s\n",
            "Batch 3730/4125 - Loss: 0.0004 - Time elapsed: 775.97s\n",
            "Batch 3740/4125 - Loss: 0.0024 - Time elapsed: 777.83s\n",
            "Batch 3750/4125 - Loss: 0.0014 - Time elapsed: 779.81s\n",
            "Batch 3760/4125 - Loss: 0.0107 - Time elapsed: 781.72s\n",
            "Batch 3770/4125 - Loss: 0.0073 - Time elapsed: 783.62s\n",
            "Batch 3780/4125 - Loss: 0.0003 - Time elapsed: 785.50s\n",
            "Batch 3790/4125 - Loss: 0.0003 - Time elapsed: 787.37s\n",
            "Batch 3800/4125 - Loss: 0.0013 - Time elapsed: 789.24s\n",
            "Batch 3810/4125 - Loss: 0.0032 - Time elapsed: 791.12s\n",
            "Batch 3820/4125 - Loss: 0.1701 - Time elapsed: 793.03s\n",
            "Batch 3830/4125 - Loss: 0.0129 - Time elapsed: 795.04s\n",
            "Batch 3840/4125 - Loss: 0.0142 - Time elapsed: 797.00s\n",
            "Batch 3850/4125 - Loss: 0.0046 - Time elapsed: 798.87s\n",
            "Batch 3860/4125 - Loss: 0.0037 - Time elapsed: 800.70s\n",
            "Batch 3870/4125 - Loss: 0.0109 - Time elapsed: 802.54s\n",
            "Batch 3880/4125 - Loss: 0.0027 - Time elapsed: 804.50s\n",
            "Batch 3890/4125 - Loss: 0.0029 - Time elapsed: 806.31s\n",
            "Batch 3900/4125 - Loss: 0.0115 - Time elapsed: 808.17s\n",
            "Batch 3910/4125 - Loss: 0.0307 - Time elapsed: 809.97s\n",
            "Batch 3920/4125 - Loss: 0.0172 - Time elapsed: 811.78s\n",
            "Batch 3930/4125 - Loss: 0.0021 - Time elapsed: 813.59s\n",
            "Batch 3940/4125 - Loss: 0.0010 - Time elapsed: 815.44s\n",
            "Batch 3950/4125 - Loss: 0.0035 - Time elapsed: 817.27s\n",
            "Batch 3960/4125 - Loss: 0.0012 - Time elapsed: 819.11s\n",
            "Batch 3970/4125 - Loss: 0.0017 - Time elapsed: 820.93s\n",
            "Batch 3980/4125 - Loss: 0.0330 - Time elapsed: 822.72s\n",
            "Batch 3990/4125 - Loss: 0.0013 - Time elapsed: 824.57s\n",
            "Batch 4000/4125 - Loss: 0.0269 - Time elapsed: 826.38s\n",
            "Batch 4010/4125 - Loss: 0.0006 - Time elapsed: 828.19s\n",
            "Batch 4020/4125 - Loss: 0.0675 - Time elapsed: 830.02s\n",
            "Batch 4030/4125 - Loss: 0.2592 - Time elapsed: 832.10s\n",
            "Batch 4040/4125 - Loss: 0.0033 - Time elapsed: 833.89s\n",
            "Batch 4050/4125 - Loss: 0.0445 - Time elapsed: 835.76s\n",
            "Batch 4060/4125 - Loss: 0.0074 - Time elapsed: 837.52s\n",
            "Batch 4070/4125 - Loss: 0.0028 - Time elapsed: 839.30s\n",
            "Batch 4080/4125 - Loss: 0.0030 - Time elapsed: 841.09s\n",
            "Batch 4090/4125 - Loss: 0.0023 - Time elapsed: 842.92s\n",
            "Batch 4100/4125 - Loss: 0.0257 - Time elapsed: 844.94s\n",
            "Batch 4110/4125 - Loss: 0.0013 - Time elapsed: 846.88s\n",
            "Batch 4120/4125 - Loss: 0.0966 - Time elapsed: 848.67s\n",
            "\n",
            "Epoch 2\n",
            "Batch 0/4125 - Loss: 0.0007 - Time elapsed: 849.50s\n",
            "Batch 10/4125 - Loss: 0.0030 - Time elapsed: 851.31s\n",
            "Batch 20/4125 - Loss: 0.0006 - Time elapsed: 853.09s\n",
            "Batch 30/4125 - Loss: 0.0026 - Time elapsed: 855.00s\n",
            "Batch 40/4125 - Loss: 0.0063 - Time elapsed: 856.82s\n",
            "Batch 50/4125 - Loss: 0.0013 - Time elapsed: 858.79s\n",
            "Batch 60/4125 - Loss: 0.0139 - Time elapsed: 860.66s\n",
            "Batch 70/4125 - Loss: 0.0043 - Time elapsed: 862.50s\n",
            "Batch 80/4125 - Loss: 0.0009 - Time elapsed: 864.30s\n",
            "Batch 90/4125 - Loss: 0.0127 - Time elapsed: 866.10s\n",
            "Batch 100/4125 - Loss: 0.0340 - Time elapsed: 867.92s\n",
            "Batch 110/4125 - Loss: 0.0074 - Time elapsed: 869.72s\n",
            "Batch 120/4125 - Loss: 0.0208 - Time elapsed: 872.16s\n",
            "Batch 130/4125 - Loss: 0.0002 - Time elapsed: 874.05s\n",
            "Batch 140/4125 - Loss: 0.0002 - Time elapsed: 875.88s\n",
            "Batch 150/4125 - Loss: 0.0002 - Time elapsed: 877.68s\n",
            "Batch 160/4125 - Loss: 0.0012 - Time elapsed: 879.53s\n",
            "Batch 170/4125 - Loss: 0.0002 - Time elapsed: 881.36s\n",
            "Batch 180/4125 - Loss: 0.0005 - Time elapsed: 883.21s\n",
            "Batch 190/4125 - Loss: 0.0011 - Time elapsed: 885.05s\n",
            "Batch 200/4125 - Loss: 0.0008 - Time elapsed: 886.94s\n",
            "Batch 210/4125 - Loss: 0.0015 - Time elapsed: 888.75s\n",
            "Batch 220/4125 - Loss: 0.0013 - Time elapsed: 890.55s\n",
            "Batch 230/4125 - Loss: 0.0003 - Time elapsed: 892.37s\n",
            "Batch 240/4125 - Loss: 0.0006 - Time elapsed: 894.18s\n",
            "Batch 250/4125 - Loss: 0.0197 - Time elapsed: 963.00s\n",
            "Batch 260/4125 - Loss: 0.0192 - Time elapsed: 964.85s\n",
            "Batch 270/4125 - Loss: 0.0015 - Time elapsed: 966.69s\n",
            "Batch 280/4125 - Loss: 0.0001 - Time elapsed: 968.77s\n",
            "Batch 290/4125 - Loss: 0.0026 - Time elapsed: 970.57s\n",
            "Batch 300/4125 - Loss: 0.0008 - Time elapsed: 972.63s\n",
            "Batch 310/4125 - Loss: 0.0002 - Time elapsed: 974.47s\n",
            "Batch 320/4125 - Loss: 0.0078 - Time elapsed: 976.51s\n",
            "Batch 330/4125 - Loss: 0.0004 - Time elapsed: 978.60s\n",
            "Batch 340/4125 - Loss: 0.0006 - Time elapsed: 980.47s\n",
            "Batch 350/4125 - Loss: 0.0004 - Time elapsed: 982.92s\n",
            "Batch 360/4125 - Loss: 0.0051 - Time elapsed: 984.82s\n",
            "Batch 370/4125 - Loss: 0.0001 - Time elapsed: 986.71s\n",
            "Batch 380/4125 - Loss: 0.0013 - Time elapsed: 988.60s\n",
            "Batch 390/4125 - Loss: 0.0063 - Time elapsed: 990.55s\n",
            "Batch 400/4125 - Loss: 0.0030 - Time elapsed: 992.54s\n",
            "Batch 410/4125 - Loss: 0.0001 - Time elapsed: 994.40s\n",
            "Batch 420/4125 - Loss: 0.0002 - Time elapsed: 996.24s\n",
            "Batch 430/4125 - Loss: 0.0003 - Time elapsed: 998.10s\n",
            "Batch 440/4125 - Loss: 0.0108 - Time elapsed: 999.96s\n",
            "Batch 450/4125 - Loss: 0.0716 - Time elapsed: 1001.82s\n",
            "Batch 460/4125 - Loss: 0.1184 - Time elapsed: 1003.77s\n",
            "Batch 470/4125 - Loss: 0.0002 - Time elapsed: 1005.77s\n",
            "Batch 480/4125 - Loss: 0.0642 - Time elapsed: 1007.66s\n",
            "Batch 490/4125 - Loss: 0.0004 - Time elapsed: 1009.47s\n",
            "Batch 500/4125 - Loss: 0.0069 - Time elapsed: 1011.30s\n",
            "Batch 510/4125 - Loss: 0.0036 - Time elapsed: 1013.13s\n",
            "Batch 520/4125 - Loss: 0.0002 - Time elapsed: 1014.94s\n",
            "Batch 530/4125 - Loss: 0.0029 - Time elapsed: 1016.76s\n",
            "Batch 540/4125 - Loss: 0.0018 - Time elapsed: 1018.72s\n",
            "Batch 550/4125 - Loss: 0.0009 - Time elapsed: 1020.50s\n",
            "Batch 560/4125 - Loss: 0.0004 - Time elapsed: 1022.36s\n",
            "Batch 570/4125 - Loss: 0.0017 - Time elapsed: 1024.13s\n",
            "Batch 580/4125 - Loss: 0.3862 - Time elapsed: 1025.91s\n",
            "Batch 590/4125 - Loss: 0.0258 - Time elapsed: 1027.74s\n",
            "Batch 600/4125 - Loss: 0.0103 - Time elapsed: 1029.55s\n",
            "Batch 610/4125 - Loss: 0.0008 - Time elapsed: 1031.63s\n",
            "Batch 620/4125 - Loss: 0.0012 - Time elapsed: 1033.46s\n",
            "Batch 630/4125 - Loss: 0.0006 - Time elapsed: 1035.22s\n",
            "Batch 640/4125 - Loss: 0.0003 - Time elapsed: 1037.00s\n",
            "Batch 650/4125 - Loss: 0.0004 - Time elapsed: 1038.78s\n",
            "Batch 660/4125 - Loss: 0.0009 - Time elapsed: 1040.53s\n",
            "Batch 670/4125 - Loss: 0.0005 - Time elapsed: 1042.49s\n",
            "Batch 680/4125 - Loss: 0.0422 - Time elapsed: 1044.39s\n",
            "Batch 690/4125 - Loss: 0.0011 - Time elapsed: 1046.27s\n",
            "Batch 700/4125 - Loss: 0.0012 - Time elapsed: 1048.06s\n",
            "Batch 710/4125 - Loss: 0.0063 - Time elapsed: 1049.88s\n",
            "Batch 720/4125 - Loss: 0.0084 - Time elapsed: 1051.69s\n",
            "Batch 730/4125 - Loss: 0.0040 - Time elapsed: 1053.50s\n",
            "Batch 740/4125 - Loss: 0.0082 - Time elapsed: 1055.34s\n",
            "Batch 750/4125 - Loss: 0.0008 - Time elapsed: 1057.15s\n",
            "Batch 760/4125 - Loss: 0.0002 - Time elapsed: 1058.96s\n",
            "Batch 770/4125 - Loss: 0.0006 - Time elapsed: 1060.89s\n",
            "Batch 780/4125 - Loss: 0.0247 - Time elapsed: 1063.26s\n",
            "Batch 790/4125 - Loss: 0.0015 - Time elapsed: 1065.11s\n",
            "Batch 800/4125 - Loss: 0.0003 - Time elapsed: 1067.04s\n",
            "Batch 810/4125 - Loss: 0.0044 - Time elapsed: 1068.83s\n",
            "Batch 820/4125 - Loss: 0.0005 - Time elapsed: 1070.76s\n",
            "Batch 830/4125 - Loss: 0.0001 - Time elapsed: 1072.70s\n",
            "Batch 840/4125 - Loss: 0.0002 - Time elapsed: 1074.53s\n",
            "Batch 850/4125 - Loss: 0.0005 - Time elapsed: 1076.37s\n",
            "Batch 860/4125 - Loss: 0.0001 - Time elapsed: 1078.23s\n",
            "Batch 870/4125 - Loss: 0.0007 - Time elapsed: 1080.07s\n",
            "Batch 880/4125 - Loss: 0.0008 - Time elapsed: 1081.90s\n",
            "Batch 890/4125 - Loss: 0.0001 - Time elapsed: 1083.75s\n",
            "Batch 900/4125 - Loss: 0.0017 - Time elapsed: 1085.63s\n",
            "Batch 910/4125 - Loss: 0.0005 - Time elapsed: 1087.52s\n",
            "Batch 920/4125 - Loss: 0.0006 - Time elapsed: 1089.33s\n",
            "Batch 930/4125 - Loss: 0.0003 - Time elapsed: 1091.43s\n",
            "Batch 940/4125 - Loss: 0.0003 - Time elapsed: 1093.30s\n",
            "Batch 950/4125 - Loss: 0.0024 - Time elapsed: 1095.15s\n",
            "Batch 960/4125 - Loss: 0.0013 - Time elapsed: 1097.04s\n",
            "Batch 970/4125 - Loss: 0.0010 - Time elapsed: 1098.91s\n",
            "Batch 980/4125 - Loss: 0.0008 - Time elapsed: 1100.74s\n",
            "Batch 990/4125 - Loss: 0.0010 - Time elapsed: 1102.60s\n",
            "Batch 1000/4125 - Loss: 0.0007 - Time elapsed: 1104.43s\n",
            "Batch 1010/4125 - Loss: 0.0002 - Time elapsed: 1106.24s\n",
            "Batch 1020/4125 - Loss: 0.0004 - Time elapsed: 1108.08s\n",
            "Batch 1030/4125 - Loss: 0.0010 - Time elapsed: 1109.89s\n",
            "Batch 1040/4125 - Loss: 0.0060 - Time elapsed: 1111.81s\n",
            "Batch 1050/4125 - Loss: 0.0011 - Time elapsed: 1113.73s\n",
            "Batch 1060/4125 - Loss: 0.0170 - Time elapsed: 1115.55s\n",
            "Batch 1070/4125 - Loss: 0.0121 - Time elapsed: 1117.35s\n",
            "Batch 1080/4125 - Loss: 0.0017 - Time elapsed: 1119.15s\n",
            "Batch 1090/4125 - Loss: 0.0977 - Time elapsed: 1120.94s\n",
            "Batch 1100/4125 - Loss: 0.1287 - Time elapsed: 1122.77s\n",
            "Batch 1110/4125 - Loss: 0.0044 - Time elapsed: 1124.83s\n",
            "Batch 1120/4125 - Loss: 0.0042 - Time elapsed: 1126.74s\n",
            "Batch 1130/4125 - Loss: 0.0004 - Time elapsed: 1128.58s\n",
            "Batch 1140/4125 - Loss: 0.0016 - Time elapsed: 1130.47s\n",
            "Batch 1150/4125 - Loss: 0.0017 - Time elapsed: 1132.28s\n",
            "Batch 1160/4125 - Loss: 0.0011 - Time elapsed: 1134.15s\n",
            "Batch 1170/4125 - Loss: 0.0020 - Time elapsed: 1136.03s\n",
            "Batch 1180/4125 - Loss: 0.0012 - Time elapsed: 1137.89s\n",
            "Batch 1190/4125 - Loss: 0.0004 - Time elapsed: 1139.69s\n",
            "Batch 1200/4125 - Loss: 0.0007 - Time elapsed: 1141.51s\n",
            "Batch 1210/4125 - Loss: 0.0016 - Time elapsed: 1143.30s\n",
            "Batch 1220/4125 - Loss: 0.0005 - Time elapsed: 1145.10s\n",
            "Batch 1230/4125 - Loss: 0.0074 - Time elapsed: 1147.67s\n",
            "Batch 1240/4125 - Loss: 0.0327 - Time elapsed: 1149.53s\n",
            "Batch 1250/4125 - Loss: 0.0002 - Time elapsed: 1151.40s\n",
            "Batch 1260/4125 - Loss: 0.0494 - Time elapsed: 1153.23s\n",
            "Batch 1270/4125 - Loss: 0.0314 - Time elapsed: 1155.05s\n",
            "Batch 1280/4125 - Loss: 0.0012 - Time elapsed: 1156.84s\n",
            "Batch 1290/4125 - Loss: 0.0023 - Time elapsed: 1158.67s\n",
            "Batch 1300/4125 - Loss: 0.0007 - Time elapsed: 1160.62s\n",
            "Batch 1310/4125 - Loss: 0.0004 - Time elapsed: 1162.73s\n",
            "Batch 1320/4125 - Loss: 0.0006 - Time elapsed: 1164.63s\n",
            "Batch 1330/4125 - Loss: 0.0174 - Time elapsed: 1166.46s\n",
            "Batch 1340/4125 - Loss: 0.0009 - Time elapsed: 1168.32s\n",
            "Batch 1350/4125 - Loss: 0.0009 - Time elapsed: 1170.38s\n",
            "Batch 1360/4125 - Loss: 0.0012 - Time elapsed: 1172.22s\n",
            "Batch 1370/4125 - Loss: 0.0018 - Time elapsed: 1174.08s\n",
            "Batch 1380/4125 - Loss: 0.0008 - Time elapsed: 1175.91s\n",
            "Batch 1390/4125 - Loss: 0.0122 - Time elapsed: 1177.90s\n",
            "Batch 1400/4125 - Loss: 0.0008 - Time elapsed: 1179.70s\n",
            "Batch 1410/4125 - Loss: 0.0013 - Time elapsed: 1181.57s\n",
            "Batch 1420/4125 - Loss: 0.0093 - Time elapsed: 1183.39s\n",
            "Batch 1430/4125 - Loss: 0.0004 - Time elapsed: 1185.20s\n",
            "Batch 1440/4125 - Loss: 0.0005 - Time elapsed: 1187.22s\n",
            "Batch 1450/4125 - Loss: 0.0005 - Time elapsed: 1190.83s\n",
            "Batch 1460/4125 - Loss: 0.0011 - Time elapsed: 1192.63s\n",
            "Batch 1470/4125 - Loss: 0.0367 - Time elapsed: 1194.42s\n",
            "Batch 1480/4125 - Loss: 0.0001 - Time elapsed: 1196.21s\n",
            "Batch 1490/4125 - Loss: 0.0002 - Time elapsed: 1198.03s\n",
            "Batch 1500/4125 - Loss: 0.0001 - Time elapsed: 1199.85s\n",
            "Batch 1510/4125 - Loss: 0.0036 - Time elapsed: 1201.70s\n",
            "Batch 1520/4125 - Loss: 0.0002 - Time elapsed: 1203.53s\n",
            "Batch 1530/4125 - Loss: 0.0004 - Time elapsed: 1205.34s\n",
            "Batch 1540/4125 - Loss: 0.0003 - Time elapsed: 1207.17s\n",
            "Batch 1550/4125 - Loss: 0.1032 - Time elapsed: 1209.09s\n",
            "Batch 1560/4125 - Loss: 0.0071 - Time elapsed: 1210.97s\n",
            "Batch 1570/4125 - Loss: 0.0003 - Time elapsed: 1212.77s\n",
            "Batch 1580/4125 - Loss: 0.0002 - Time elapsed: 1214.73s\n",
            "Batch 1590/4125 - Loss: 0.0010 - Time elapsed: 1216.66s\n",
            "Batch 1600/4125 - Loss: 0.0002 - Time elapsed: 1218.47s\n",
            "Batch 1610/4125 - Loss: 0.0098 - Time elapsed: 1220.25s\n",
            "Batch 1620/4125 - Loss: 0.0108 - Time elapsed: 1222.11s\n",
            "Batch 1630/4125 - Loss: 0.0013 - Time elapsed: 1223.89s\n",
            "Batch 1640/4125 - Loss: 0.0013 - Time elapsed: 1225.68s\n",
            "Batch 1650/4125 - Loss: 0.0002 - Time elapsed: 1227.52s\n",
            "Batch 1660/4125 - Loss: 0.0003 - Time elapsed: 1229.45s\n",
            "Batch 1670/4125 - Loss: 0.0029 - Time elapsed: 1231.27s\n",
            "Batch 1680/4125 - Loss: 0.0002 - Time elapsed: 1233.09s\n",
            "Batch 1690/4125 - Loss: 0.0004 - Time elapsed: 1237.92s\n",
            "Batch 1700/4125 - Loss: 0.0001 - Time elapsed: 1239.75s\n",
            "Batch 1710/4125 - Loss: 0.0006 - Time elapsed: 1241.71s\n",
            "Batch 1720/4125 - Loss: 0.0045 - Time elapsed: 1243.51s\n",
            "Batch 1730/4125 - Loss: 0.0005 - Time elapsed: 1245.32s\n",
            "Batch 1740/4125 - Loss: 0.0019 - Time elapsed: 1247.11s\n",
            "Batch 1750/4125 - Loss: 0.0031 - Time elapsed: 1248.90s\n",
            "Batch 1760/4125 - Loss: 0.0100 - Time elapsed: 1250.69s\n",
            "Batch 1770/4125 - Loss: 0.0007 - Time elapsed: 1252.55s\n",
            "Batch 1780/4125 - Loss: 0.0004 - Time elapsed: 1254.40s\n",
            "Batch 1790/4125 - Loss: 0.0297 - Time elapsed: 1256.25s\n",
            "Batch 1800/4125 - Loss: 0.2050 - Time elapsed: 1258.10s\n",
            "Batch 1810/4125 - Loss: 0.0002 - Time elapsed: 1259.91s\n",
            "Batch 1820/4125 - Loss: 0.0033 - Time elapsed: 1261.71s\n",
            "Batch 1830/4125 - Loss: 0.0099 - Time elapsed: 1263.54s\n",
            "Batch 1840/4125 - Loss: 0.0016 - Time elapsed: 1265.38s\n",
            "Batch 1850/4125 - Loss: 0.0001 - Time elapsed: 1267.31s\n",
            "Batch 1860/4125 - Loss: 0.0017 - Time elapsed: 1269.24s\n",
            "Batch 1870/4125 - Loss: 0.0136 - Time elapsed: 1271.07s\n",
            "Batch 1880/4125 - Loss: 0.2089 - Time elapsed: 1272.90s\n",
            "Batch 1890/4125 - Loss: 0.0002 - Time elapsed: 1274.72s\n",
            "Batch 1900/4125 - Loss: 0.0145 - Time elapsed: 1276.55s\n",
            "Batch 1910/4125 - Loss: 0.0001 - Time elapsed: 1278.35s\n",
            "Batch 1920/4125 - Loss: 0.0001 - Time elapsed: 1280.87s\n",
            "Batch 1930/4125 - Loss: 0.0010 - Time elapsed: 1282.87s\n",
            "Batch 1940/4125 - Loss: 0.0010 - Time elapsed: 1285.81s\n",
            "Batch 1950/4125 - Loss: 0.0613 - Time elapsed: 1287.64s\n",
            "Batch 1960/4125 - Loss: 0.0007 - Time elapsed: 1289.51s\n",
            "Batch 1970/4125 - Loss: 0.0008 - Time elapsed: 1291.35s\n",
            "Batch 1980/4125 - Loss: 0.0003 - Time elapsed: 1293.17s\n",
            "Batch 1990/4125 - Loss: 0.0026 - Time elapsed: 1295.22s\n",
            "Batch 2000/4125 - Loss: 0.0001 - Time elapsed: 1297.03s\n",
            "Batch 2010/4125 - Loss: 0.0013 - Time elapsed: 1298.84s\n",
            "Batch 2020/4125 - Loss: 0.0001 - Time elapsed: 1300.64s\n",
            "Batch 2030/4125 - Loss: 0.0012 - Time elapsed: 1302.46s\n",
            "Batch 2040/4125 - Loss: 0.0316 - Time elapsed: 1304.28s\n",
            "Batch 2050/4125 - Loss: 0.0002 - Time elapsed: 1306.06s\n",
            "Batch 2060/4125 - Loss: 0.0004 - Time elapsed: 1307.94s\n",
            "Batch 2070/4125 - Loss: 0.0025 - Time elapsed: 1309.81s\n",
            "Batch 2080/4125 - Loss: 0.0008 - Time elapsed: 1311.85s\n",
            "Batch 2090/4125 - Loss: 0.0622 - Time elapsed: 1313.64s\n",
            "Batch 2100/4125 - Loss: 0.0004 - Time elapsed: 1315.49s\n",
            "Batch 2110/4125 - Loss: 0.0015 - Time elapsed: 1317.29s\n",
            "Batch 2120/4125 - Loss: 0.0262 - Time elapsed: 1319.33s\n",
            "Batch 2130/4125 - Loss: 0.0004 - Time elapsed: 1321.27s\n",
            "Batch 2140/4125 - Loss: 0.0057 - Time elapsed: 1323.08s\n",
            "Batch 2150/4125 - Loss: 0.0003 - Time elapsed: 1324.90s\n",
            "Batch 2160/4125 - Loss: 0.0006 - Time elapsed: 1327.31s\n",
            "Batch 2170/4125 - Loss: 0.0045 - Time elapsed: 1329.14s\n",
            "Batch 2180/4125 - Loss: 0.0002 - Time elapsed: 1330.96s\n",
            "Batch 2190/4125 - Loss: 0.0002 - Time elapsed: 1332.85s\n",
            "Batch 2200/4125 - Loss: 0.0022 - Time elapsed: 1334.79s\n",
            "Batch 2210/4125 - Loss: 0.1584 - Time elapsed: 1336.62s\n",
            "Batch 2220/4125 - Loss: 0.0032 - Time elapsed: 1338.48s\n",
            "Batch 2230/4125 - Loss: 0.0018 - Time elapsed: 1340.30s\n",
            "Batch 2240/4125 - Loss: 0.0002 - Time elapsed: 1342.19s\n",
            "Batch 2250/4125 - Loss: 0.0003 - Time elapsed: 1344.01s\n",
            "Batch 2260/4125 - Loss: 0.0003 - Time elapsed: 1346.00s\n",
            "Batch 2270/4125 - Loss: 0.0009 - Time elapsed: 1347.89s\n",
            "Batch 2280/4125 - Loss: 0.0023 - Time elapsed: 1349.70s\n",
            "Batch 2290/4125 - Loss: 0.0005 - Time elapsed: 1351.50s\n",
            "Batch 2300/4125 - Loss: 0.0138 - Time elapsed: 1353.30s\n",
            "Batch 2310/4125 - Loss: 0.0018 - Time elapsed: 1357.17s\n",
            "Batch 2320/4125 - Loss: 0.0002 - Time elapsed: 1358.98s\n",
            "Batch 2330/4125 - Loss: 0.0001 - Time elapsed: 1361.11s\n",
            "Batch 2340/4125 - Loss: 0.0019 - Time elapsed: 1362.92s\n",
            "Batch 2350/4125 - Loss: 0.0032 - Time elapsed: 1364.76s\n",
            "Batch 2360/4125 - Loss: 0.0001 - Time elapsed: 1366.62s\n",
            "Batch 2370/4125 - Loss: 0.0005 - Time elapsed: 1369.31s\n",
            "Batch 2380/4125 - Loss: 0.0004 - Time elapsed: 1371.10s\n",
            "Batch 2390/4125 - Loss: 0.0004 - Time elapsed: 1373.07s\n",
            "Batch 2400/4125 - Loss: 0.0201 - Time elapsed: 1375.04s\n",
            "Batch 2410/4125 - Loss: 0.0046 - Time elapsed: 1376.84s\n",
            "Batch 2420/4125 - Loss: 0.0064 - Time elapsed: 1378.63s\n",
            "Batch 2430/4125 - Loss: 0.0007 - Time elapsed: 1380.49s\n",
            "Batch 2440/4125 - Loss: 0.0005 - Time elapsed: 1382.29s\n",
            "Batch 2450/4125 - Loss: 0.0029 - Time elapsed: 1384.17s\n",
            "Batch 2460/4125 - Loss: 0.0003 - Time elapsed: 1386.08s\n",
            "Batch 2470/4125 - Loss: 0.0006 - Time elapsed: 1387.98s\n",
            "Batch 2480/4125 - Loss: 0.0006 - Time elapsed: 1389.80s\n",
            "Batch 2490/4125 - Loss: 0.0054 - Time elapsed: 1391.61s\n",
            "Batch 2500/4125 - Loss: 0.0113 - Time elapsed: 1393.41s\n",
            "Batch 2510/4125 - Loss: 0.0769 - Time elapsed: 1395.26s\n",
            "Batch 2520/4125 - Loss: 0.0006 - Time elapsed: 1397.07s\n",
            "Batch 2530/4125 - Loss: 0.0954 - Time elapsed: 1399.11s\n",
            "Batch 2540/4125 - Loss: 0.0823 - Time elapsed: 1400.92s\n",
            "Batch 2550/4125 - Loss: 0.0002 - Time elapsed: 1402.72s\n",
            "Batch 2560/4125 - Loss: 0.0006 - Time elapsed: 1404.55s\n",
            "Batch 2570/4125 - Loss: 0.0021 - Time elapsed: 1406.39s\n",
            "Batch 2580/4125 - Loss: 0.0036 - Time elapsed: 1408.18s\n",
            "Batch 2590/4125 - Loss: 0.0244 - Time elapsed: 1410.65s\n",
            "Batch 2600/4125 - Loss: 0.0010 - Time elapsed: 1412.58s\n",
            "Batch 2610/4125 - Loss: 0.0001 - Time elapsed: 1414.46s\n",
            "Batch 2620/4125 - Loss: 0.0161 - Time elapsed: 1416.32s\n",
            "Batch 2630/4125 - Loss: 0.1215 - Time elapsed: 1418.10s\n",
            "Batch 2640/4125 - Loss: 0.1962 - Time elapsed: 1419.89s\n",
            "Batch 2650/4125 - Loss: 0.0022 - Time elapsed: 1421.77s\n",
            "Batch 2660/4125 - Loss: 0.0004 - Time elapsed: 1423.60s\n",
            "Batch 2670/4125 - Loss: 0.0015 - Time elapsed: 1425.60s\n",
            "Batch 2680/4125 - Loss: 0.0219 - Time elapsed: 1427.95s\n",
            "Batch 2690/4125 - Loss: 0.0004 - Time elapsed: 1429.75s\n",
            "Batch 2700/4125 - Loss: 0.0110 - Time elapsed: 1431.61s\n",
            "Batch 2710/4125 - Loss: 0.0011 - Time elapsed: 1433.44s\n",
            "Batch 2720/4125 - Loss: 0.0020 - Time elapsed: 1435.24s\n",
            "Batch 2730/4125 - Loss: 0.0004 - Time elapsed: 1437.02s\n",
            "Batch 2740/4125 - Loss: 0.0002 - Time elapsed: 1438.89s\n",
            "Batch 2750/4125 - Loss: 0.0015 - Time elapsed: 1440.78s\n",
            "Batch 2760/4125 - Loss: 0.0001 - Time elapsed: 1442.60s\n",
            "Batch 2770/4125 - Loss: 0.0006 - Time elapsed: 1444.38s\n",
            "Batch 2780/4125 - Loss: 0.0270 - Time elapsed: 1446.22s\n",
            "Batch 2790/4125 - Loss: 0.0040 - Time elapsed: 1448.07s\n",
            "Batch 2800/4125 - Loss: 0.0021 - Time elapsed: 1449.90s\n",
            "Batch 2810/4125 - Loss: 0.0005 - Time elapsed: 1452.10s\n",
            "Batch 2820/4125 - Loss: 0.0005 - Time elapsed: 1453.98s\n",
            "Batch 2830/4125 - Loss: 0.0017 - Time elapsed: 1455.83s\n",
            "Batch 2840/4125 - Loss: 0.0074 - Time elapsed: 1457.64s\n",
            "Batch 2850/4125 - Loss: 0.0124 - Time elapsed: 1459.45s\n",
            "Batch 2860/4125 - Loss: 0.0020 - Time elapsed: 1461.25s\n",
            "Batch 2870/4125 - Loss: 0.0050 - Time elapsed: 1463.16s\n",
            "Batch 2880/4125 - Loss: 0.0019 - Time elapsed: 1465.02s\n",
            "Batch 2890/4125 - Loss: 0.0180 - Time elapsed: 1466.91s\n",
            "Batch 2900/4125 - Loss: 0.0015 - Time elapsed: 1468.68s\n",
            "Batch 2910/4125 - Loss: 0.0092 - Time elapsed: 1470.51s\n",
            "Batch 2920/4125 - Loss: 0.0010 - Time elapsed: 1472.35s\n",
            "Batch 2930/4125 - Loss: 0.0002 - Time elapsed: 1474.17s\n",
            "Batch 2940/4125 - Loss: 0.0002 - Time elapsed: 1476.03s\n",
            "Batch 2950/4125 - Loss: 0.2138 - Time elapsed: 1477.83s\n",
            "Batch 2960/4125 - Loss: 0.0161 - Time elapsed: 1479.69s\n",
            "Batch 2970/4125 - Loss: 0.0357 - Time elapsed: 1481.52s\n",
            "Batch 2980/4125 - Loss: 0.0003 - Time elapsed: 1483.34s\n",
            "Batch 2990/4125 - Loss: 0.0068 - Time elapsed: 1485.13s\n",
            "Batch 3000/4125 - Loss: 0.0930 - Time elapsed: 1486.95s\n",
            "Batch 3010/4125 - Loss: 0.0037 - Time elapsed: 1488.93s\n",
            "Batch 3020/4125 - Loss: 0.1288 - Time elapsed: 1490.88s\n",
            "Batch 3030/4125 - Loss: 0.0004 - Time elapsed: 1492.75s\n",
            "Batch 3040/4125 - Loss: 0.0100 - Time elapsed: 1494.61s\n",
            "Batch 3050/4125 - Loss: 0.0019 - Time elapsed: 1496.48s\n",
            "Batch 3060/4125 - Loss: 0.0204 - Time elapsed: 1498.31s\n",
            "Batch 3070/4125 - Loss: 0.0065 - Time elapsed: 1500.13s\n",
            "Batch 3080/4125 - Loss: 0.0356 - Time elapsed: 1501.94s\n",
            "Batch 3090/4125 - Loss: 0.0002 - Time elapsed: 1504.02s\n",
            "Batch 3100/4125 - Loss: 0.0002 - Time elapsed: 1505.86s\n",
            "Batch 3110/4125 - Loss: 0.1190 - Time elapsed: 1507.70s\n",
            "Batch 3120/4125 - Loss: 0.0044 - Time elapsed: 1509.49s\n",
            "Batch 3130/4125 - Loss: 0.0021 - Time elapsed: 1511.40s\n",
            "Batch 3140/4125 - Loss: 0.0001 - Time elapsed: 1513.23s\n",
            "Batch 3150/4125 - Loss: 0.0001 - Time elapsed: 1515.05s\n",
            "Batch 3160/4125 - Loss: 0.0001 - Time elapsed: 1517.11s\n",
            "Batch 3170/4125 - Loss: 0.0744 - Time elapsed: 1520.03s\n",
            "Batch 3180/4125 - Loss: 0.0048 - Time elapsed: 1521.84s\n",
            "Batch 3190/4125 - Loss: 0.0000 - Time elapsed: 1523.71s\n",
            "Batch 3200/4125 - Loss: 0.0001 - Time elapsed: 1525.51s\n",
            "Batch 3210/4125 - Loss: 0.0003 - Time elapsed: 1527.33s\n",
            "Batch 3220/4125 - Loss: 0.0028 - Time elapsed: 1529.13s\n",
            "Batch 3230/4125 - Loss: 0.0030 - Time elapsed: 1531.04s\n",
            "Batch 3240/4125 - Loss: 0.0014 - Time elapsed: 1532.93s\n",
            "Batch 3250/4125 - Loss: 0.0067 - Time elapsed: 1534.74s\n",
            "Batch 3260/4125 - Loss: 0.0007 - Time elapsed: 1536.57s\n",
            "Batch 3270/4125 - Loss: 0.0014 - Time elapsed: 1538.39s\n",
            "Batch 3280/4125 - Loss: 0.0003 - Time elapsed: 1540.19s\n",
            "Batch 3290/4125 - Loss: 0.0018 - Time elapsed: 1542.02s\n",
            "Batch 3300/4125 - Loss: 0.5379 - Time elapsed: 1543.83s\n",
            "Batch 3310/4125 - Loss: 0.0006 - Time elapsed: 1545.85s\n",
            "Batch 3320/4125 - Loss: 0.0071 - Time elapsed: 1547.66s\n",
            "Batch 3330/4125 - Loss: 0.0011 - Time elapsed: 1549.51s\n",
            "Batch 3340/4125 - Loss: 0.0011 - Time elapsed: 1551.32s\n",
            "Batch 3350/4125 - Loss: 0.0095 - Time elapsed: 1553.17s\n",
            "Batch 3360/4125 - Loss: 0.0003 - Time elapsed: 1554.99s\n",
            "Batch 3370/4125 - Loss: 0.0004 - Time elapsed: 1556.92s\n",
            "Batch 3380/4125 - Loss: 0.0055 - Time elapsed: 1558.76s\n",
            "Batch 3390/4125 - Loss: 0.0002 - Time elapsed: 1560.59s\n",
            "Batch 3400/4125 - Loss: 0.0143 - Time elapsed: 1562.52s\n",
            "Batch 3410/4125 - Loss: 0.0032 - Time elapsed: 1564.45s\n",
            "Batch 3420/4125 - Loss: 0.0006 - Time elapsed: 1566.31s\n",
            "Batch 3430/4125 - Loss: 0.0003 - Time elapsed: 1568.11s\n",
            "Batch 3440/4125 - Loss: 0.0025 - Time elapsed: 1570.03s\n",
            "Batch 3450/4125 - Loss: 0.1579 - Time elapsed: 1572.13s\n",
            "Batch 3460/4125 - Loss: 0.0003 - Time elapsed: 1574.19s\n",
            "Batch 3470/4125 - Loss: 0.0231 - Time elapsed: 1576.00s\n",
            "Batch 3480/4125 - Loss: 0.0025 - Time elapsed: 1577.83s\n",
            "Batch 3490/4125 - Loss: 0.0082 - Time elapsed: 1579.68s\n",
            "Batch 3500/4125 - Loss: 0.0005 - Time elapsed: 1581.47s\n",
            "Batch 3510/4125 - Loss: 0.0038 - Time elapsed: 1583.43s\n",
            "Batch 3520/4125 - Loss: 0.0002 - Time elapsed: 1585.29s\n",
            "Batch 3530/4125 - Loss: 0.0002 - Time elapsed: 1587.09s\n",
            "Batch 3540/4125 - Loss: 0.0153 - Time elapsed: 1588.90s\n",
            "Batch 3550/4125 - Loss: 0.0004 - Time elapsed: 1590.74s\n",
            "Batch 3560/4125 - Loss: 0.0012 - Time elapsed: 1592.58s\n",
            "Batch 3570/4125 - Loss: 0.0001 - Time elapsed: 1594.39s\n",
            "Batch 3580/4125 - Loss: 0.0002 - Time elapsed: 1596.57s\n",
            "Batch 3590/4125 - Loss: 0.0291 - Time elapsed: 1598.63s\n",
            "Batch 3600/4125 - Loss: 0.0002 - Time elapsed: 1603.60s\n",
            "Batch 3610/4125 - Loss: 0.0041 - Time elapsed: 1605.44s\n",
            "Batch 3620/4125 - Loss: 0.0008 - Time elapsed: 1607.22s\n",
            "Batch 3630/4125 - Loss: 0.0032 - Time elapsed: 1609.25s\n",
            "Batch 3640/4125 - Loss: 0.0590 - Time elapsed: 1611.35s\n",
            "Batch 3650/4125 - Loss: 0.0030 - Time elapsed: 1613.15s\n",
            "Batch 3660/4125 - Loss: 0.0090 - Time elapsed: 1615.46s\n",
            "Batch 3670/4125 - Loss: 0.0267 - Time elapsed: 1617.25s\n",
            "Batch 3680/4125 - Loss: 0.0094 - Time elapsed: 1619.13s\n",
            "Batch 3690/4125 - Loss: 0.0007 - Time elapsed: 1620.95s\n",
            "Batch 3700/4125 - Loss: 0.0015 - Time elapsed: 1622.84s\n",
            "Batch 3710/4125 - Loss: 0.0012 - Time elapsed: 1624.75s\n",
            "Batch 3720/4125 - Loss: 0.0004 - Time elapsed: 1626.55s\n",
            "Batch 3730/4125 - Loss: 0.0012 - Time elapsed: 1628.43s\n",
            "Batch 3740/4125 - Loss: 0.0003 - Time elapsed: 1630.26s\n",
            "Batch 3750/4125 - Loss: 0.0507 - Time elapsed: 1632.07s\n",
            "Batch 3760/4125 - Loss: 0.0006 - Time elapsed: 1633.89s\n",
            "Batch 3770/4125 - Loss: 0.0023 - Time elapsed: 1635.82s\n",
            "Batch 3780/4125 - Loss: 0.0032 - Time elapsed: 1637.64s\n",
            "Batch 3790/4125 - Loss: 0.0022 - Time elapsed: 1639.52s\n",
            "Batch 3800/4125 - Loss: 0.0007 - Time elapsed: 1641.35s\n",
            "Batch 3810/4125 - Loss: 0.0004 - Time elapsed: 1643.19s\n",
            "Batch 3820/4125 - Loss: 0.0002 - Time elapsed: 1645.06s\n",
            "Batch 3830/4125 - Loss: 0.0011 - Time elapsed: 1646.86s\n",
            "Batch 3840/4125 - Loss: 0.2769 - Time elapsed: 1649.23s\n",
            "Batch 3850/4125 - Loss: 0.0006 - Time elapsed: 1652.19s\n",
            "Batch 3860/4125 - Loss: 0.0006 - Time elapsed: 1654.00s\n",
            "Batch 3870/4125 - Loss: 0.0016 - Time elapsed: 1655.80s\n",
            "Batch 3880/4125 - Loss: 0.0005 - Time elapsed: 1657.64s\n",
            "Batch 3890/4125 - Loss: 0.0004 - Time elapsed: 1659.46s\n",
            "Batch 3900/4125 - Loss: 0.0025 - Time elapsed: 1661.41s\n",
            "Batch 3910/4125 - Loss: 0.0002 - Time elapsed: 1663.32s\n",
            "Batch 3920/4125 - Loss: 0.0013 - Time elapsed: 1665.27s\n",
            "Batch 3930/4125 - Loss: 0.0001 - Time elapsed: 1667.09s\n",
            "Batch 3940/4125 - Loss: 0.0001 - Time elapsed: 1668.90s\n",
            "Batch 3950/4125 - Loss: 0.0008 - Time elapsed: 1670.72s\n",
            "Batch 3960/4125 - Loss: 0.0001 - Time elapsed: 1672.54s\n",
            "Batch 3970/4125 - Loss: 0.0002 - Time elapsed: 1674.39s\n",
            "Batch 3980/4125 - Loss: 0.0002 - Time elapsed: 1676.29s\n",
            "Batch 3990/4125 - Loss: 0.0039 - Time elapsed: 1678.09s\n",
            "Batch 4000/4125 - Loss: 0.0002 - Time elapsed: 1679.92s\n",
            "Batch 4010/4125 - Loss: 0.0005 - Time elapsed: 1681.80s\n",
            "Batch 4020/4125 - Loss: 0.0004 - Time elapsed: 1683.63s\n",
            "Batch 4030/4125 - Loss: 0.0001 - Time elapsed: 1685.43s\n",
            "Batch 4040/4125 - Loss: 0.0003 - Time elapsed: 1687.47s\n",
            "Batch 4050/4125 - Loss: 0.0005 - Time elapsed: 1689.31s\n",
            "Batch 4060/4125 - Loss: 0.1937 - Time elapsed: 1691.14s\n",
            "Batch 4070/4125 - Loss: 0.0010 - Time elapsed: 1692.95s\n",
            "Batch 4080/4125 - Loss: 0.0001 - Time elapsed: 1695.12s\n",
            "Batch 4090/4125 - Loss: 0.0003 - Time elapsed: 1696.92s\n",
            "Batch 4100/4125 - Loss: 0.0001 - Time elapsed: 1698.73s\n",
            "Batch 4110/4125 - Loss: 0.0002 - Time elapsed: 1700.63s\n",
            "Batch 4120/4125 - Loss: 0.0001 - Time elapsed: 1702.55s\n",
            "\n",
            "Epoch 3\n",
            "Batch 0/4125 - Loss: 0.0001 - Time elapsed: 1703.35s\n",
            "Batch 10/4125 - Loss: 0.0012 - Time elapsed: 1705.16s\n",
            "Batch 20/4125 - Loss: 0.0004 - Time elapsed: 1707.05s\n",
            "Batch 30/4125 - Loss: 0.0001 - Time elapsed: 1708.85s\n",
            "Batch 40/4125 - Loss: 0.0001 - Time elapsed: 1710.74s\n",
            "Batch 50/4125 - Loss: 0.0002 - Time elapsed: 1712.55s\n",
            "Batch 60/4125 - Loss: 0.0001 - Time elapsed: 1714.60s\n",
            "Batch 70/4125 - Loss: 0.0001 - Time elapsed: 1716.45s\n",
            "Batch 80/4125 - Loss: 0.0002 - Time elapsed: 1718.28s\n",
            "Batch 90/4125 - Loss: 0.0001 - Time elapsed: 1720.08s\n",
            "Batch 100/4125 - Loss: 0.0002 - Time elapsed: 1721.97s\n",
            "Batch 110/4125 - Loss: 0.0001 - Time elapsed: 1723.77s\n",
            "Batch 120/4125 - Loss: 0.1846 - Time elapsed: 1725.60s\n",
            "Batch 130/4125 - Loss: 0.0001 - Time elapsed: 1727.45s\n",
            "Batch 140/4125 - Loss: 0.0003 - Time elapsed: 1729.35s\n",
            "Batch 150/4125 - Loss: 0.0005 - Time elapsed: 1731.15s\n",
            "Batch 160/4125 - Loss: 0.0001 - Time elapsed: 1733.03s\n",
            "Batch 170/4125 - Loss: 0.0003 - Time elapsed: 1734.81s\n",
            "Batch 180/4125 - Loss: 0.0002 - Time elapsed: 1736.65s\n",
            "Batch 190/4125 - Loss: 0.0003 - Time elapsed: 1738.48s\n",
            "Batch 200/4125 - Loss: 0.0005 - Time elapsed: 1742.50s\n",
            "Batch 210/4125 - Loss: 0.0001 - Time elapsed: 1744.32s\n",
            "Batch 220/4125 - Loss: 0.0003 - Time elapsed: 1746.09s\n",
            "Batch 230/4125 - Loss: 0.0001 - Time elapsed: 1747.90s\n",
            "Batch 240/4125 - Loss: 0.0001 - Time elapsed: 1749.71s\n",
            "Batch 250/4125 - Loss: 0.0015 - Time elapsed: 1751.53s\n",
            "Batch 260/4125 - Loss: 0.0004 - Time elapsed: 1753.37s\n",
            "Batch 270/4125 - Loss: 0.0001 - Time elapsed: 1755.44s\n",
            "Batch 280/4125 - Loss: 0.0002 - Time elapsed: 1757.25s\n",
            "Batch 290/4125 - Loss: 0.0007 - Time elapsed: 1759.08s\n",
            "Batch 300/4125 - Loss: 0.0084 - Time elapsed: 1760.96s\n",
            "Batch 310/4125 - Loss: 0.0001 - Time elapsed: 1764.72s\n",
            "Batch 320/4125 - Loss: 0.0001 - Time elapsed: 1766.57s\n",
            "Batch 330/4125 - Loss: 0.0001 - Time elapsed: 1768.62s\n",
            "Batch 340/4125 - Loss: 0.0000 - Time elapsed: 1770.52s\n",
            "Batch 350/4125 - Loss: 0.0001 - Time elapsed: 1772.35s\n",
            "Batch 360/4125 - Loss: 0.0002 - Time elapsed: 1774.28s\n",
            "Batch 370/4125 - Loss: 0.0004 - Time elapsed: 1776.06s\n",
            "Batch 380/4125 - Loss: 0.0000 - Time elapsed: 1777.87s\n",
            "Batch 390/4125 - Loss: 0.0092 - Time elapsed: 1779.80s\n",
            "Batch 400/4125 - Loss: 0.0001 - Time elapsed: 1781.67s\n",
            "Batch 410/4125 - Loss: 0.0000 - Time elapsed: 1783.54s\n",
            "Batch 420/4125 - Loss: 0.0005 - Time elapsed: 1785.38s\n",
            "Batch 430/4125 - Loss: 0.0001 - Time elapsed: 1787.22s\n",
            "Batch 440/4125 - Loss: 0.0003 - Time elapsed: 1789.03s\n",
            "Batch 450/4125 - Loss: 0.0000 - Time elapsed: 1790.84s\n",
            "Batch 460/4125 - Loss: 0.0001 - Time elapsed: 1792.67s\n",
            "Batch 470/4125 - Loss: 0.0000 - Time elapsed: 1794.64s\n",
            "Batch 480/4125 - Loss: 0.0001 - Time elapsed: 1796.46s\n",
            "Batch 490/4125 - Loss: 0.0000 - Time elapsed: 1798.25s\n",
            "Batch 500/4125 - Loss: 0.0001 - Time elapsed: 1800.08s\n",
            "Batch 510/4125 - Loss: 0.0000 - Time elapsed: 1801.91s\n",
            "Batch 520/4125 - Loss: 0.0090 - Time elapsed: 1803.75s\n",
            "Batch 530/4125 - Loss: 0.0001 - Time elapsed: 1805.55s\n",
            "Batch 540/4125 - Loss: 0.0001 - Time elapsed: 1807.40s\n",
            "Batch 550/4125 - Loss: 0.3803 - Time elapsed: 1809.26s\n",
            "Batch 560/4125 - Loss: 0.0012 - Time elapsed: 1811.05s\n",
            "Batch 570/4125 - Loss: 0.0002 - Time elapsed: 1812.85s\n",
            "Batch 580/4125 - Loss: 0.0002 - Time elapsed: 1814.71s\n",
            "Batch 590/4125 - Loss: 0.0002 - Time elapsed: 1816.51s\n",
            "Batch 600/4125 - Loss: 0.0039 - Time elapsed: 1818.42s\n",
            "Batch 610/4125 - Loss: 0.0015 - Time elapsed: 1820.38s\n",
            "Batch 620/4125 - Loss: 0.0026 - Time elapsed: 1822.44s\n",
            "Batch 630/4125 - Loss: 0.0002 - Time elapsed: 1824.26s\n",
            "Batch 640/4125 - Loss: 0.0051 - Time elapsed: 1826.09s\n",
            "Batch 650/4125 - Loss: 0.0020 - Time elapsed: 1827.91s\n",
            "Batch 660/4125 - Loss: 0.0001 - Time elapsed: 1829.95s\n",
            "Batch 670/4125 - Loss: 0.0001 - Time elapsed: 1831.93s\n",
            "Batch 680/4125 - Loss: 0.0004 - Time elapsed: 1833.79s\n",
            "Batch 690/4125 - Loss: 0.0006 - Time elapsed: 1835.67s\n",
            "Batch 700/4125 - Loss: 0.0002 - Time elapsed: 1837.51s\n",
            "Batch 710/4125 - Loss: 0.0002 - Time elapsed: 1839.30s\n",
            "Batch 720/4125 - Loss: 0.0001 - Time elapsed: 1841.15s\n",
            "Batch 730/4125 - Loss: 0.0007 - Time elapsed: 1843.00s\n",
            "Batch 740/4125 - Loss: 0.0033 - Time elapsed: 1844.79s\n",
            "Batch 750/4125 - Loss: 0.0001 - Time elapsed: 1846.69s\n",
            "Batch 760/4125 - Loss: 0.0041 - Time elapsed: 1848.90s\n",
            "Batch 770/4125 - Loss: 0.0016 - Time elapsed: 1850.69s\n",
            "Batch 780/4125 - Loss: 0.0413 - Time elapsed: 1852.49s\n",
            "Batch 790/4125 - Loss: 0.0002 - Time elapsed: 1854.28s\n",
            "Batch 800/4125 - Loss: 0.0005 - Time elapsed: 1856.07s\n",
            "Batch 810/4125 - Loss: 0.0451 - Time elapsed: 1857.88s\n",
            "Batch 820/4125 - Loss: 0.0001 - Time elapsed: 1859.74s\n",
            "Batch 830/4125 - Loss: 0.0002 - Time elapsed: 1861.65s\n",
            "Batch 840/4125 - Loss: 0.0001 - Time elapsed: 1863.44s\n",
            "Batch 850/4125 - Loss: 0.0001 - Time elapsed: 1865.28s\n",
            "Batch 860/4125 - Loss: 0.0002 - Time elapsed: 1867.08s\n",
            "Batch 870/4125 - Loss: 0.0003 - Time elapsed: 1868.99s\n",
            "Batch 880/4125 - Loss: 0.0002 - Time elapsed: 1870.79s\n",
            "Batch 890/4125 - Loss: 0.0007 - Time elapsed: 1872.67s\n",
            "Batch 900/4125 - Loss: 0.0002 - Time elapsed: 1874.59s\n",
            "Batch 910/4125 - Loss: 0.0001 - Time elapsed: 1876.38s\n",
            "Batch 920/4125 - Loss: 0.0016 - Time elapsed: 1878.17s\n",
            "Batch 930/4125 - Loss: 0.0002 - Time elapsed: 1880.05s\n",
            "Batch 940/4125 - Loss: 0.0001 - Time elapsed: 1881.87s\n",
            "Batch 950/4125 - Loss: 0.0000 - Time elapsed: 1883.67s\n",
            "Batch 960/4125 - Loss: 0.0075 - Time elapsed: 1885.53s\n",
            "Batch 970/4125 - Loss: 0.0001 - Time elapsed: 1887.61s\n",
            "Batch 980/4125 - Loss: 0.0002 - Time elapsed: 1889.41s\n",
            "Batch 990/4125 - Loss: 0.0002 - Time elapsed: 1891.20s\n",
            "Batch 1000/4125 - Loss: 0.0001 - Time elapsed: 1893.02s\n",
            "Batch 1010/4125 - Loss: 0.0000 - Time elapsed: 1894.92s\n",
            "Batch 1020/4125 - Loss: 0.0001 - Time elapsed: 1896.72s\n",
            "Batch 1030/4125 - Loss: 0.0001 - Time elapsed: 1898.57s\n",
            "Batch 1040/4125 - Loss: 0.0001 - Time elapsed: 1900.38s\n",
            "Batch 1050/4125 - Loss: 0.0001 - Time elapsed: 1902.20s\n",
            "Batch 1060/4125 - Loss: 0.0070 - Time elapsed: 1904.49s\n",
            "Batch 1070/4125 - Loss: 0.0001 - Time elapsed: 1906.31s\n",
            "Batch 1080/4125 - Loss: 0.0001 - Time elapsed: 1908.20s\n",
            "Batch 1090/4125 - Loss: 0.0003 - Time elapsed: 1910.00s\n",
            "Batch 1100/4125 - Loss: 0.0122 - Time elapsed: 1911.94s\n",
            "Batch 1110/4125 - Loss: 0.0001 - Time elapsed: 1913.96s\n",
            "Batch 1120/4125 - Loss: 0.0003 - Time elapsed: 1915.76s\n",
            "Batch 1130/4125 - Loss: 0.0003 - Time elapsed: 1917.55s\n",
            "Batch 1140/4125 - Loss: 0.0001 - Time elapsed: 1919.34s\n",
            "Batch 1150/4125 - Loss: 0.0004 - Time elapsed: 1921.13s\n",
            "Batch 1160/4125 - Loss: 0.0001 - Time elapsed: 1922.99s\n",
            "Batch 1170/4125 - Loss: 0.0001 - Time elapsed: 1925.53s\n",
            "Batch 1180/4125 - Loss: 0.0003 - Time elapsed: 1927.38s\n",
            "Batch 1190/4125 - Loss: 0.0001 - Time elapsed: 1929.17s\n",
            "Batch 1200/4125 - Loss: 0.0001 - Time elapsed: 1931.00s\n",
            "Batch 1210/4125 - Loss: 0.0002 - Time elapsed: 1932.81s\n",
            "Batch 1220/4125 - Loss: 0.0023 - Time elapsed: 1934.65s\n",
            "Batch 1230/4125 - Loss: 0.0001 - Time elapsed: 1936.47s\n",
            "Batch 1240/4125 - Loss: 0.0013 - Time elapsed: 1938.39s\n",
            "Batch 1250/4125 - Loss: 0.0001 - Time elapsed: 1940.21s\n",
            "Batch 1260/4125 - Loss: 0.0009 - Time elapsed: 1942.59s\n",
            "Batch 1270/4125 - Loss: 0.0164 - Time elapsed: 1944.45s\n",
            "Batch 1280/4125 - Loss: 0.0002 - Time elapsed: 1946.26s\n",
            "Batch 1290/4125 - Loss: 0.0067 - Time elapsed: 1948.08s\n",
            "Batch 1300/4125 - Loss: 0.0004 - Time elapsed: 1949.88s\n",
            "Batch 1310/4125 - Loss: 0.0007 - Time elapsed: 1951.77s\n",
            "Batch 1320/4125 - Loss: 0.0001 - Time elapsed: 1953.66s\n",
            "Batch 1330/4125 - Loss: 0.0012 - Time elapsed: 1955.46s\n",
            "Batch 1340/4125 - Loss: 0.0002 - Time elapsed: 1957.29s\n",
            "Batch 1350/4125 - Loss: 0.0002 - Time elapsed: 1959.12s\n",
            "Batch 1360/4125 - Loss: 0.0003 - Time elapsed: 1961.01s\n",
            "Batch 1370/4125 - Loss: 0.0004 - Time elapsed: 1962.80s\n",
            "Batch 1380/4125 - Loss: 0.0002 - Time elapsed: 1964.81s\n",
            "Batch 1390/4125 - Loss: 0.0003 - Time elapsed: 1966.64s\n",
            "Batch 1400/4125 - Loss: 0.0001 - Time elapsed: 1968.45s\n",
            "Batch 1410/4125 - Loss: 0.0009 - Time elapsed: 1970.25s\n",
            "Batch 1420/4125 - Loss: 0.0001 - Time elapsed: 1972.11s\n",
            "Batch 1430/4125 - Loss: 0.0027 - Time elapsed: 1973.92s\n",
            "Batch 1440/4125 - Loss: 0.0013 - Time elapsed: 1975.84s\n",
            "Batch 1450/4125 - Loss: 0.0003 - Time elapsed: 1977.72s\n",
            "Batch 1460/4125 - Loss: 0.0022 - Time elapsed: 1979.64s\n",
            "Batch 1470/4125 - Loss: 0.0730 - Time elapsed: 1981.46s\n",
            "Batch 1480/4125 - Loss: 0.0001 - Time elapsed: 1983.25s\n",
            "Batch 1490/4125 - Loss: 0.0001 - Time elapsed: 1985.06s\n",
            "Batch 1500/4125 - Loss: 0.0001 - Time elapsed: 1986.92s\n",
            "Batch 1510/4125 - Loss: 0.0001 - Time elapsed: 1988.78s\n",
            "Batch 1520/4125 - Loss: 0.0005 - Time elapsed: 1990.63s\n",
            "Batch 1530/4125 - Loss: 0.0001 - Time elapsed: 1992.51s\n",
            "Batch 1540/4125 - Loss: 0.0002 - Time elapsed: 1995.40s\n",
            "Batch 1550/4125 - Loss: 0.0001 - Time elapsed: 1997.22s\n",
            "Batch 1560/4125 - Loss: 0.0000 - Time elapsed: 1999.04s\n",
            "Batch 1570/4125 - Loss: 0.0012 - Time elapsed: 2001.03s\n",
            "Batch 1580/4125 - Loss: 0.0525 - Time elapsed: 2002.99s\n",
            "Batch 1590/4125 - Loss: 0.0002 - Time elapsed: 2005.00s\n",
            "Batch 1600/4125 - Loss: 0.0001 - Time elapsed: 2006.87s\n",
            "Batch 1610/4125 - Loss: 0.0000 - Time elapsed: 2008.65s\n",
            "Batch 1620/4125 - Loss: 0.0000 - Time elapsed: 2010.47s\n",
            "Batch 1630/4125 - Loss: 0.0000 - Time elapsed: 2012.27s\n",
            "Batch 1640/4125 - Loss: 0.0001 - Time elapsed: 2014.16s\n",
            "Batch 1650/4125 - Loss: 0.0003 - Time elapsed: 2015.95s\n",
            "Batch 1660/4125 - Loss: 0.0399 - Time elapsed: 2017.89s\n",
            "Batch 1670/4125 - Loss: 0.0012 - Time elapsed: 2019.68s\n",
            "Batch 1680/4125 - Loss: 0.1006 - Time elapsed: 2021.48s\n",
            "Batch 1690/4125 - Loss: 0.0007 - Time elapsed: 2026.49s\n",
            "Batch 1700/4125 - Loss: 0.0002 - Time elapsed: 2028.33s\n",
            "Batch 1710/4125 - Loss: 0.0021 - Time elapsed: 2030.25s\n",
            "Batch 1720/4125 - Loss: 0.0046 - Time elapsed: 2032.23s\n",
            "Batch 1730/4125 - Loss: 0.0001 - Time elapsed: 2034.04s\n",
            "Batch 1740/4125 - Loss: 0.0039 - Time elapsed: 2035.85s\n",
            "Batch 1750/4125 - Loss: 0.0002 - Time elapsed: 2037.77s\n",
            "Batch 1760/4125 - Loss: 0.0004 - Time elapsed: 2039.57s\n",
            "Batch 1770/4125 - Loss: 0.0002 - Time elapsed: 2041.38s\n",
            "Batch 1780/4125 - Loss: 0.0001 - Time elapsed: 2043.32s\n",
            "Batch 1790/4125 - Loss: 0.0001 - Time elapsed: 2045.40s\n",
            "Batch 1800/4125 - Loss: 0.0017 - Time elapsed: 2047.23s\n",
            "Batch 1810/4125 - Loss: 0.0001 - Time elapsed: 2049.03s\n",
            "Batch 1820/4125 - Loss: 0.0039 - Time elapsed: 2050.86s\n",
            "Batch 1830/4125 - Loss: 0.0000 - Time elapsed: 2052.70s\n",
            "Batch 1840/4125 - Loss: 0.0000 - Time elapsed: 2054.50s\n",
            "Batch 1850/4125 - Loss: 0.0001 - Time elapsed: 2056.51s\n",
            "Batch 1860/4125 - Loss: 0.0000 - Time elapsed: 2058.37s\n",
            "Batch 1870/4125 - Loss: 0.0001 - Time elapsed: 2060.19s\n",
            "Batch 1880/4125 - Loss: 0.0001 - Time elapsed: 2062.01s\n",
            "Batch 1890/4125 - Loss: 0.0001 - Time elapsed: 2063.82s\n",
            "Batch 1900/4125 - Loss: 0.0002 - Time elapsed: 2065.71s\n",
            "Batch 1910/4125 - Loss: 0.1186 - Time elapsed: 2067.53s\n",
            "Batch 1920/4125 - Loss: 0.0002 - Time elapsed: 2070.42s\n",
            "Batch 1930/4125 - Loss: 0.0003 - Time elapsed: 2072.24s\n",
            "Batch 1940/4125 - Loss: 0.0811 - Time elapsed: 2074.04s\n",
            "Batch 1950/4125 - Loss: 0.0001 - Time elapsed: 2075.86s\n",
            "Batch 1960/4125 - Loss: 0.0120 - Time elapsed: 2077.65s\n",
            "Batch 1970/4125 - Loss: 0.0002 - Time elapsed: 2079.43s\n",
            "Batch 1980/4125 - Loss: 0.0002 - Time elapsed: 2081.23s\n",
            "Batch 1990/4125 - Loss: 0.0001 - Time elapsed: 2083.16s\n",
            "Batch 2000/4125 - Loss: 0.0001 - Time elapsed: 2084.96s\n",
            "Batch 2010/4125 - Loss: 0.0001 - Time elapsed: 2086.78s\n",
            "Batch 2020/4125 - Loss: 0.0014 - Time elapsed: 2088.59s\n",
            "Batch 2030/4125 - Loss: 0.0012 - Time elapsed: 2090.38s\n",
            "Batch 2040/4125 - Loss: 0.0007 - Time elapsed: 2092.19s\n",
            "Batch 2050/4125 - Loss: 0.0050 - Time elapsed: 2093.97s\n",
            "Batch 2060/4125 - Loss: 0.0044 - Time elapsed: 2096.07s\n",
            "Batch 2070/4125 - Loss: 0.0000 - Time elapsed: 2097.89s\n",
            "Batch 2080/4125 - Loss: 0.0000 - Time elapsed: 2099.70s\n",
            "Batch 2090/4125 - Loss: 0.0000 - Time elapsed: 2101.50s\n",
            "Batch 2100/4125 - Loss: 0.0006 - Time elapsed: 2103.31s\n",
            "Batch 2110/4125 - Loss: 0.0019 - Time elapsed: 2105.11s\n",
            "Batch 2120/4125 - Loss: 0.0002 - Time elapsed: 2106.92s\n",
            "Batch 2130/4125 - Loss: 0.1233 - Time elapsed: 2108.74s\n",
            "Batch 2140/4125 - Loss: 0.0001 - Time elapsed: 2110.59s\n",
            "Batch 2150/4125 - Loss: 0.0069 - Time elapsed: 2112.38s\n",
            "Batch 2160/4125 - Loss: 0.0037 - Time elapsed: 2114.16s\n",
            "Batch 2170/4125 - Loss: 0.0016 - Time elapsed: 2116.03s\n",
            "Batch 2180/4125 - Loss: 0.0002 - Time elapsed: 2118.00s\n",
            "Batch 2190/4125 - Loss: 0.0038 - Time elapsed: 2119.80s\n",
            "Batch 2200/4125 - Loss: 0.0001 - Time elapsed: 2121.92s\n",
            "Batch 2210/4125 - Loss: 0.0028 - Time elapsed: 2123.89s\n",
            "Batch 2220/4125 - Loss: 0.0001 - Time elapsed: 2125.70s\n",
            "Batch 2230/4125 - Loss: 0.0001 - Time elapsed: 2127.49s\n",
            "Batch 2240/4125 - Loss: 0.0001 - Time elapsed: 2129.31s\n",
            "Batch 2250/4125 - Loss: 0.0001 - Time elapsed: 2131.10s\n",
            "Batch 2260/4125 - Loss: 0.0053 - Time elapsed: 2132.90s\n",
            "Batch 2270/4125 - Loss: 0.1753 - Time elapsed: 2134.89s\n",
            "Batch 2280/4125 - Loss: 0.0002 - Time elapsed: 2136.75s\n",
            "Batch 2290/4125 - Loss: 0.0002 - Time elapsed: 2138.55s\n",
            "Batch 2300/4125 - Loss: 0.0002 - Time elapsed: 2140.40s\n",
            "Batch 2310/4125 - Loss: 0.0002 - Time elapsed: 2143.97s\n",
            "Batch 2320/4125 - Loss: 0.0000 - Time elapsed: 2145.95s\n",
            "Batch 2330/4125 - Loss: 0.0003 - Time elapsed: 2147.92s\n",
            "Batch 2340/4125 - Loss: 0.0001 - Time elapsed: 2149.77s\n",
            "Batch 2350/4125 - Loss: 0.0010 - Time elapsed: 2151.57s\n",
            "Batch 2360/4125 - Loss: 0.0111 - Time elapsed: 2153.38s\n",
            "Batch 2370/4125 - Loss: 0.0000 - Time elapsed: 2155.19s\n",
            "Batch 2380/4125 - Loss: 0.0001 - Time elapsed: 2156.99s\n",
            "Batch 2390/4125 - Loss: 0.0001 - Time elapsed: 2158.88s\n",
            "Batch 2400/4125 - Loss: 0.0001 - Time elapsed: 2160.80s\n",
            "Batch 2410/4125 - Loss: 0.0001 - Time elapsed: 2163.03s\n",
            "Batch 2420/4125 - Loss: 0.0001 - Time elapsed: 2164.86s\n",
            "Batch 2430/4125 - Loss: 0.0001 - Time elapsed: 2166.70s\n",
            "Batch 2440/4125 - Loss: 0.0003 - Time elapsed: 2168.53s\n",
            "Batch 2450/4125 - Loss: 0.0402 - Time elapsed: 2170.33s\n",
            "Batch 2460/4125 - Loss: 0.0001 - Time elapsed: 2172.13s\n",
            "Batch 2470/4125 - Loss: 0.0000 - Time elapsed: 2174.20s\n",
            "Batch 2480/4125 - Loss: 0.0001 - Time elapsed: 2176.10s\n",
            "Batch 2490/4125 - Loss: 0.0017 - Time elapsed: 2177.93s\n",
            "Batch 2500/4125 - Loss: 0.0007 - Time elapsed: 2179.87s\n",
            "Batch 2510/4125 - Loss: 0.0018 - Time elapsed: 2181.67s\n",
            "Batch 2520/4125 - Loss: 0.0034 - Time elapsed: 2184.08s\n",
            "Batch 2530/4125 - Loss: 0.0002 - Time elapsed: 2185.89s\n",
            "Batch 2540/4125 - Loss: 0.0001 - Time elapsed: 2187.80s\n",
            "Batch 2550/4125 - Loss: 0.0308 - Time elapsed: 2189.67s\n",
            "Batch 2560/4125 - Loss: 0.0008 - Time elapsed: 2191.54s\n",
            "Batch 2570/4125 - Loss: 0.1243 - Time elapsed: 2193.40s\n",
            "Batch 2580/4125 - Loss: 0.0002 - Time elapsed: 2195.26s\n",
            "Batch 2590/4125 - Loss: 0.0005 - Time elapsed: 2197.09s\n",
            "Batch 2600/4125 - Loss: 0.0066 - Time elapsed: 2198.93s\n",
            "Batch 2610/4125 - Loss: 0.0010 - Time elapsed: 2200.94s\n",
            "Batch 2620/4125 - Loss: 0.0001 - Time elapsed: 2202.80s\n",
            "Batch 2630/4125 - Loss: 0.0001 - Time elapsed: 2204.66s\n",
            "Batch 2640/4125 - Loss: 0.0006 - Time elapsed: 2206.50s\n",
            "Batch 2650/4125 - Loss: 0.0001 - Time elapsed: 2208.66s\n",
            "Batch 2660/4125 - Loss: 0.0001 - Time elapsed: 2210.48s\n",
            "Batch 2670/4125 - Loss: 0.0000 - Time elapsed: 2212.32s\n",
            "Batch 2680/4125 - Loss: 0.0001 - Time elapsed: 2214.20s\n",
            "Batch 2690/4125 - Loss: 0.0039 - Time elapsed: 2216.07s\n",
            "Batch 2700/4125 - Loss: 0.0668 - Time elapsed: 2217.93s\n",
            "Batch 2710/4125 - Loss: 0.0001 - Time elapsed: 2219.72s\n",
            "Batch 2720/4125 - Loss: 0.0001 - Time elapsed: 2221.60s\n",
            "Batch 2730/4125 - Loss: 0.0005 - Time elapsed: 2223.42s\n",
            "Batch 2740/4125 - Loss: 0.0002 - Time elapsed: 2225.31s\n",
            "Batch 2750/4125 - Loss: 0.0017 - Time elapsed: 2227.21s\n",
            "Batch 2760/4125 - Loss: 0.0003 - Time elapsed: 2229.11s\n",
            "Batch 2770/4125 - Loss: 0.0134 - Time elapsed: 2230.92s\n",
            "Batch 2780/4125 - Loss: 0.0001 - Time elapsed: 2232.74s\n",
            "Batch 2790/4125 - Loss: 0.0043 - Time elapsed: 2234.57s\n",
            "Batch 2800/4125 - Loss: 0.0001 - Time elapsed: 2236.52s\n",
            "Batch 2810/4125 - Loss: 0.0059 - Time elapsed: 2238.32s\n",
            "Batch 2820/4125 - Loss: 0.0018 - Time elapsed: 2240.25s\n",
            "Batch 2830/4125 - Loss: 0.0000 - Time elapsed: 2242.11s\n",
            "Batch 2840/4125 - Loss: 0.0006 - Time elapsed: 2243.93s\n",
            "Batch 2850/4125 - Loss: 0.0004 - Time elapsed: 2245.72s\n",
            "Batch 2860/4125 - Loss: 0.0001 - Time elapsed: 2247.79s\n",
            "Batch 2870/4125 - Loss: 0.0001 - Time elapsed: 2249.66s\n",
            "Batch 2880/4125 - Loss: 0.0000 - Time elapsed: 2251.50s\n",
            "Batch 2890/4125 - Loss: 0.0001 - Time elapsed: 2253.66s\n",
            "Batch 2900/4125 - Loss: 0.0001 - Time elapsed: 2255.50s\n",
            "Batch 2910/4125 - Loss: 0.0001 - Time elapsed: 2257.95s\n",
            "Batch 2920/4125 - Loss: 0.0001 - Time elapsed: 2259.79s\n",
            "Batch 2930/4125 - Loss: 0.0000 - Time elapsed: 2261.70s\n",
            "Batch 2940/4125 - Loss: 0.0001 - Time elapsed: 2263.52s\n",
            "Batch 2950/4125 - Loss: 0.0001 - Time elapsed: 2265.48s\n",
            "Batch 2960/4125 - Loss: 0.0001 - Time elapsed: 2267.45s\n",
            "Batch 2970/4125 - Loss: 0.0000 - Time elapsed: 2269.33s\n",
            "Batch 2980/4125 - Loss: 0.0001 - Time elapsed: 2271.19s\n",
            "Batch 2990/4125 - Loss: 0.0000 - Time elapsed: 2273.07s\n",
            "Batch 3000/4125 - Loss: 0.0006 - Time elapsed: 2274.87s\n",
            "Batch 3010/4125 - Loss: 0.0001 - Time elapsed: 2276.66s\n",
            "Batch 3020/4125 - Loss: 0.0000 - Time elapsed: 2278.51s\n",
            "Batch 3030/4125 - Loss: 0.0085 - Time elapsed: 2280.44s\n",
            "Batch 3040/4125 - Loss: 0.0000 - Time elapsed: 2282.33s\n",
            "Batch 3050/4125 - Loss: 0.1506 - Time elapsed: 2284.15s\n",
            "Batch 3060/4125 - Loss: 0.0001 - Time elapsed: 2286.00s\n",
            "Batch 3070/4125 - Loss: 0.0000 - Time elapsed: 2287.83s\n",
            "Batch 3080/4125 - Loss: 0.0001 - Time elapsed: 2289.67s\n",
            "Batch 3090/4125 - Loss: 0.0000 - Time elapsed: 2295.96s\n",
            "Batch 3100/4125 - Loss: 0.0009 - Time elapsed: 2297.74s\n",
            "Batch 3110/4125 - Loss: 0.0001 - Time elapsed: 2299.52s\n",
            "Batch 3120/4125 - Loss: 0.0000 - Time elapsed: 2301.40s\n",
            "Batch 3130/4125 - Loss: 0.0002 - Time elapsed: 2303.22s\n",
            "Batch 3140/4125 - Loss: 0.0011 - Time elapsed: 2305.02s\n",
            "Batch 3150/4125 - Loss: 0.0003 - Time elapsed: 2306.95s\n",
            "Batch 3160/4125 - Loss: 0.0000 - Time elapsed: 2308.77s\n",
            "Batch 3170/4125 - Loss: 0.0000 - Time elapsed: 2310.65s\n",
            "Batch 3180/4125 - Loss: 0.0001 - Time elapsed: 2312.45s\n",
            "Batch 3190/4125 - Loss: 0.0001 - Time elapsed: 2314.25s\n",
            "Batch 3200/4125 - Loss: 0.0003 - Time elapsed: 2316.04s\n",
            "Batch 3210/4125 - Loss: 0.0000 - Time elapsed: 2317.84s\n",
            "Batch 3220/4125 - Loss: 0.0070 - Time elapsed: 2321.00s\n",
            "Batch 3230/4125 - Loss: 0.0002 - Time elapsed: 2322.83s\n",
            "Batch 3240/4125 - Loss: 0.0001 - Time elapsed: 2324.65s\n",
            "Batch 3250/4125 - Loss: 0.0001 - Time elapsed: 2326.59s\n",
            "Batch 3260/4125 - Loss: 0.0033 - Time elapsed: 2329.19s\n",
            "Batch 3270/4125 - Loss: 0.0002 - Time elapsed: 2331.01s\n",
            "Batch 3280/4125 - Loss: 0.0030 - Time elapsed: 2333.38s\n",
            "Batch 3290/4125 - Loss: 0.0001 - Time elapsed: 2335.24s\n",
            "Batch 3300/4125 - Loss: 0.0001 - Time elapsed: 2337.09s\n",
            "Batch 3310/4125 - Loss: 0.0000 - Time elapsed: 2338.89s\n",
            "Batch 3320/4125 - Loss: 0.0000 - Time elapsed: 2340.70s\n",
            "Batch 3330/4125 - Loss: 0.0001 - Time elapsed: 2342.57s\n",
            "Batch 3340/4125 - Loss: 0.0218 - Time elapsed: 2344.40s\n",
            "Batch 3350/4125 - Loss: 0.0001 - Time elapsed: 2346.40s\n",
            "Batch 3360/4125 - Loss: 0.1783 - Time elapsed: 2348.30s\n",
            "Batch 3370/4125 - Loss: 0.0015 - Time elapsed: 2350.12s\n",
            "Batch 3380/4125 - Loss: 0.0001 - Time elapsed: 2351.94s\n",
            "Batch 3390/4125 - Loss: 0.0003 - Time elapsed: 2353.76s\n",
            "Batch 3400/4125 - Loss: 0.0021 - Time elapsed: 2355.73s\n",
            "Batch 3410/4125 - Loss: 0.0001 - Time elapsed: 2357.55s\n",
            "Batch 3420/4125 - Loss: 0.0081 - Time elapsed: 2359.40s\n",
            "Batch 3430/4125 - Loss: 0.0001 - Time elapsed: 2361.27s\n",
            "Batch 3440/4125 - Loss: 0.0001 - Time elapsed: 2363.07s\n",
            "Batch 3450/4125 - Loss: 0.0000 - Time elapsed: 2364.90s\n",
            "Batch 3460/4125 - Loss: 0.0001 - Time elapsed: 2366.67s\n",
            "Batch 3470/4125 - Loss: 0.0000 - Time elapsed: 2368.46s\n",
            "Batch 3480/4125 - Loss: 0.0001 - Time elapsed: 2370.26s\n",
            "Batch 3490/4125 - Loss: 0.0002 - Time elapsed: 2372.09s\n",
            "Batch 3500/4125 - Loss: 0.0015 - Time elapsed: 2373.99s\n",
            "Batch 3510/4125 - Loss: 0.0004 - Time elapsed: 2375.80s\n",
            "Batch 3520/4125 - Loss: 0.0001 - Time elapsed: 2377.66s\n",
            "Batch 3530/4125 - Loss: 0.0070 - Time elapsed: 2379.52s\n",
            "Batch 3540/4125 - Loss: 0.0016 - Time elapsed: 2381.49s\n",
            "Batch 3550/4125 - Loss: 0.0007 - Time elapsed: 2383.28s\n",
            "Batch 3560/4125 - Loss: 0.0002 - Time elapsed: 2385.22s\n",
            "Batch 3570/4125 - Loss: 0.0005 - Time elapsed: 2387.24s\n",
            "Batch 3580/4125 - Loss: 0.0001 - Time elapsed: 2389.07s\n",
            "Batch 3590/4125 - Loss: 0.0003 - Time elapsed: 2390.89s\n",
            "Batch 3600/4125 - Loss: 0.0004 - Time elapsed: 2459.46s\n",
            "Batch 3610/4125 - Loss: 0.0000 - Time elapsed: 2461.23s\n",
            "Batch 3620/4125 - Loss: 0.0001 - Time elapsed: 2463.05s\n",
            "Batch 3630/4125 - Loss: 0.0007 - Time elapsed: 2465.15s\n",
            "Batch 3640/4125 - Loss: 0.0002 - Time elapsed: 2467.06s\n",
            "Batch 3650/4125 - Loss: 0.0006 - Time elapsed: 2468.92s\n",
            "Batch 3660/4125 - Loss: 0.0012 - Time elapsed: 2470.77s\n",
            "Batch 3670/4125 - Loss: 0.0126 - Time elapsed: 2472.60s\n",
            "Batch 3680/4125 - Loss: 0.0343 - Time elapsed: 2474.47s\n",
            "Batch 3690/4125 - Loss: 0.0003 - Time elapsed: 2476.34s\n",
            "Batch 3700/4125 - Loss: 0.0008 - Time elapsed: 2478.38s\n",
            "Batch 3710/4125 - Loss: 0.0003 - Time elapsed: 2480.28s\n",
            "Batch 3720/4125 - Loss: 0.0002 - Time elapsed: 2482.23s\n",
            "Batch 3730/4125 - Loss: 0.0014 - Time elapsed: 2484.09s\n",
            "Batch 3740/4125 - Loss: 0.0001 - Time elapsed: 2485.97s\n",
            "Batch 3750/4125 - Loss: 0.0001 - Time elapsed: 2487.84s\n",
            "Batch 3760/4125 - Loss: 0.0016 - Time elapsed: 2489.78s\n",
            "Batch 3770/4125 - Loss: 0.0001 - Time elapsed: 2491.73s\n",
            "Batch 3780/4125 - Loss: 0.0002 - Time elapsed: 2493.58s\n",
            "Batch 3790/4125 - Loss: 0.0007 - Time elapsed: 2495.57s\n",
            "Batch 3800/4125 - Loss: 0.0008 - Time elapsed: 2497.42s\n",
            "Batch 3810/4125 - Loss: 0.0006 - Time elapsed: 2499.42s\n",
            "Batch 3820/4125 - Loss: 0.0002 - Time elapsed: 2501.25s\n",
            "Batch 3830/4125 - Loss: 0.0002 - Time elapsed: 2503.08s\n",
            "Batch 3840/4125 - Loss: 0.0033 - Time elapsed: 2504.92s\n",
            "Batch 3850/4125 - Loss: 0.0003 - Time elapsed: 2506.75s\n",
            "Batch 3860/4125 - Loss: 0.0009 - Time elapsed: 2508.61s\n",
            "Batch 3870/4125 - Loss: 0.0006 - Time elapsed: 2510.41s\n",
            "Batch 3880/4125 - Loss: 0.0001 - Time elapsed: 2512.19s\n",
            "Batch 3890/4125 - Loss: 0.0001 - Time elapsed: 2513.99s\n",
            "Batch 3900/4125 - Loss: 0.0002 - Time elapsed: 2515.81s\n",
            "Batch 3910/4125 - Loss: 0.0001 - Time elapsed: 2517.95s\n",
            "Batch 3920/4125 - Loss: 0.0001 - Time elapsed: 2519.73s\n",
            "Batch 3930/4125 - Loss: 0.0001 - Time elapsed: 2521.54s\n",
            "Batch 3940/4125 - Loss: 0.0001 - Time elapsed: 2523.33s\n",
            "Batch 3950/4125 - Loss: 0.0114 - Time elapsed: 2525.13s\n",
            "Batch 3960/4125 - Loss: 0.0001 - Time elapsed: 2526.96s\n",
            "Batch 3970/4125 - Loss: 0.0001 - Time elapsed: 2528.90s\n",
            "Batch 3980/4125 - Loss: 0.0121 - Time elapsed: 2531.06s\n",
            "Batch 3990/4125 - Loss: 0.0006 - Time elapsed: 2533.25s\n",
            "Batch 4000/4125 - Loss: 0.0003 - Time elapsed: 2535.02s\n",
            "Batch 4010/4125 - Loss: 0.0001 - Time elapsed: 2536.82s\n",
            "Batch 4020/4125 - Loss: 0.0001 - Time elapsed: 2538.65s\n",
            "Batch 4030/4125 - Loss: 0.0001 - Time elapsed: 2540.46s\n",
            "Batch 4040/4125 - Loss: 0.0002 - Time elapsed: 2542.28s\n",
            "Batch 4050/4125 - Loss: 0.0003 - Time elapsed: 2544.08s\n",
            "Batch 4060/4125 - Loss: 0.0001 - Time elapsed: 2545.93s\n",
            "Batch 4070/4125 - Loss: 0.0019 - Time elapsed: 2547.70s\n",
            "Batch 4080/4125 - Loss: 0.0008 - Time elapsed: 2549.55s\n",
            "Batch 4090/4125 - Loss: 0.0013 - Time elapsed: 2551.35s\n",
            "Batch 4100/4125 - Loss: 0.0001 - Time elapsed: 2553.15s\n",
            "Batch 4110/4125 - Loss: 0.0007 - Time elapsed: 2554.98s\n",
            "Batch 4120/4125 - Loss: 0.0001 - Time elapsed: 2556.84s\n",
            "\n",
            "✅ Training complete.\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9912    0.9945    0.9928      7935\n",
            "           1     0.9948    0.9918    0.9933      8563\n",
            "\n",
            "    accuracy                         0.9931     16498\n",
            "   macro avg     0.9930    0.9931    0.9931     16498\n",
            "weighted avg     0.9931    0.9931    0.9931     16498\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ✅ Step 2: Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "\n",
        "# ✅ Step 3: Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ✅ Step 4: Load phishing datasets\n",
        "path = '/content/drive/MyDrive/dataset thesis/'\n",
        "files = {\n",
        "    \"phishing_email\": \"phishing_email.csv\",\n",
        "    \"enron\": \"Enron.csv\",\n",
        "    \"ling\": \"Ling.csv\",\n",
        "    \"nazario\": \"Nazario.csv\",\n",
        "    \"nigerian_fraud\": \"Nigerian_Fraud.csv\",\n",
        "    \"spamassassin\": \"SpamAssasin.csv\",\n",
        "    \"ceas_08\": \"CEAS_08.csv\"\n",
        "}\n",
        "\n",
        "data = []\n",
        "for name, file in files.items():\n",
        "    df = pd.read_csv(path + file)\n",
        "    df['source'] = name\n",
        "    data.append(df)\n",
        "\n",
        "# ✅ Step 5: Combine and preprocess\n",
        "df_all = pd.concat(data, ignore_index=True)\n",
        "df_all = df_all[['text_combined', 'label']]  # Adjust if needed\n",
        "df_all.dropna(inplace=True)\n",
        "\n",
        "# ✅ Step 6: Encode labels if not numeric\n",
        "if df_all['label'].dtype == 'object':\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    df_all['label'] = le.fit_transform(df_all['label'])\n",
        "\n",
        "# ✅ Step 7: Train/test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df_all['text_combined'].tolist(), df_all['label'].tolist(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Step 8: Tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# ✅ Step 9: Optimized Dataset class (on-the-fly tokenization)\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# ✅ Step 10: Load datasets\n",
        "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = TextDataset(test_texts, test_labels, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# ✅ Step 11: Define model\n",
        "class DistilBertClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBertClassifier, self).__init__()\n",
        "        print(\"Loading DistilBERT model...\")\n",
        "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        print(\"Model loaded.\")\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state[:, 0]\n",
        "        dropped = self.dropout(hidden_state)\n",
        "        return self.classifier(dropped)\n",
        "\n",
        "# ✅ Step 12: Initialize model\n",
        "model = DistilBertClassifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# ✅ Step 13: Training loop\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    print(f\"\\nEpoch {epoch + 1}\")\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Batch {i}/{len(train_loader)} - Loss: {loss.item():.4f} - Time elapsed: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "print(\"\\n✅ Training complete.\")\n",
        "\n",
        "# ✅ Step 14: Evaluation\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"\\n✅ Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, digits=4))\n",
        "\n",
        "evaluate(model, test_loader)"
      ]
    }
  ]
}